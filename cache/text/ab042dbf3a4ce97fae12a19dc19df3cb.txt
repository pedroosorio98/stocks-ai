1 Investor PresentationOctober 2024 2 Except for the historical information contained herein, certain matters in this presentation including, but not limited to, statements as to:our financial position; our markets and market opportunity; demand and supply; demand and growth drivers; the benefits, impact, performance, features and availability of our products and technologies; Blackwell platform being in full production – expanding to support x86 and NVIDIA Grace, air and liquid cooling, NVLink 8-GPU to NVLink 72-GPU, InfiniBand and Ethernet, CSP, regional AI factories, and enterprise platforms; AI training continuing scaling law; the $1T installed base of general-purpose CPU data center infrastructure being modernized to a new GPU accelerated computing paradigm; AI Factories expanding the data center footprint to $2T and beyond in the coming years; companies in every industry operating AI factories as the digital twin of their workforce, manufacturing plants, and products; every company producing digital intelligence; tokens being the transformed into intelligent responses and actions of digital nurses, tutors, customer service agents, and chip designers, manufacturing robots and autonomous cars, and weather prediction agents to warn us of storms; some companies building and operating AI factories, while others renting; countries awakening to the need to treat its data as a national resource and AI factories as an essential national infrastructure; data being able to be transformed into the sovereign AI for its companies, startups, universities and governments;NVIDIA being able to address many major workloads across a wide range of industries; accelerated computing enabling full-stack optimization from algorithm to GPU architecture; AI scaling laws driving exponential demand for compute; NVIDIA being the leading inference platform; inference compute scaling exponentially with “long thinking”; compute demand for AI scaling exponentially; model size, multi-modality, synthetic data generation and reinforcement learning scaling computing capacity by ~4x per year; NVIDIA NVLink enabling new level of AI training & inference scaling; NVIDIA addressing the entire AI market; NVIDIA being able to address every industry from healthcare, manufacturing, and transportation to retail, CSPs, and telecommunications; NVIDIA AI platform and ecosystem reaching every market; AI driving investment cycle and significant returns; AI accelerating scientific discovery, creativity, and productivity across industries; AI agents being able to generate documents, review contracts, help code and debug software, operationalize marketing campaigns, andreview medical images; social media, search and e-commerce apps using deep recommenders; creators being able to generate stunning, photorealistic images or 3D objects with a single text prompt; call center agents augmented with AI chatbots being able to scale to deliver customer care during peak times, run in-the-loop with customer support to provide better service, and capture every interaction to build institutional knowledge in high turnover industries; drug discovery seeing order-of-magnitude workflow acceleration using generative for candidate drug generation and target selection; manufacturing using generative AI to generate ideas to inspire designers, accelerate the planning and layout of factories and warehouses, and for self-learning robots that can handle diverse tasks in changing work environments; climate tech scientists using AI to discover new materials for better batteries, emulate complex physics to predict long-range weather, estimate carbon-capture sites, optimize wind farm output; companies leveraging AI to unlock new monetizable applications, enhance employee productivity, and transform their business models; industrial AI applications serving large markets – including 10M factories, 200K warehouses, billions of humanoid robots, and 100M autos manufactured each year; specialized AI co-pilots collaborating with employees, being given access to necessary data, using platform tools like SAP, Snowflake, or ServiceNow, and collaborating with other AI agents; the world’s companies hiring billions of AI agents in its workforce; NVIDIA AI Enterprise enabling IT ecosystem with state-of-the-art AI models and libraries to build agentic AI; physical AI embodying robotic systems; nations are awakening to the imperative to produce artificial intelligence using their own infrastructure, data, workforces and business networks; and nations building domestic computing capacity through various models are forward-looking statements. These forward-looking statements and any other forward-looking statements that go beyond historical facts that are made in this presentation are subject to risks and uncertainties that may cause actual results to differ materially. Important factors that could cause actual results to differ materially include: global economic conditions; our reliance on third parties to manufacture, assemble, package and test our products; the impact of technological development and competition; development of new products and technologies or enhancements to our existing product and technologies; market acceptance of our products or our partners' products; design, manufacturing or software defects; changes in consumer preferences and demands; changes in industry standards and interfaces; unexpected loss of performance of our products or technologies when integrated into systems and other factors. NVIDIA has based these forward-looking statements largely on its current expectations and projections about future events and trends that it believes may affect its financial condition, results of operations, business strategy, short-term and long-term business operations and objectives, and financial needs. These forward-looking statements are subject to a number of risks and uncertainties, and you should not rely upon the forward-looking statements as predictions of future events. The future events and trends discussed in this presentation may not occur and actual results could differ materially and adversely from those anticipated or implied in the forward-looking statements. Although NVIDIA believes that the expectations reflected in the forward-looking statements are reasonable, the company cannot guarantee that future results, levels of activity, performance, achievements or events and circumstances reflected in the forward-looking statements will occur. Except as required by law, NVIDIA disclaims any obligation to update these forward-looking statements to reflect future events or circumstances. For a complete discussion of factors that could materially affect our financial results and operations, please refer to the reports we file from time to time with the SEC, including our most recent Annual Report on Form 10-K, Quarterly Reports on Form 10-Q, and Current Reports on Form 8-K. Copies of reports we file with the SEC are posted on our website and are available from NVIDIA without charge.Many of the products and features described herein remain in various stages and will be offered on a when-and-if-available basis. The statements within are not intended to be, and should not be interpreted as a commitment, promise, or legal obligation, and the development, release, and timing of any features or functionalities described for our products is subject to change and remains at the sole discretion of NVIDIA. NVIDIA will have no liability for failure to deliver or delay in the delivery of any of the products, features or functions set forth herein.NVIDIA uses certain non-GAAP measures in this presentation including non-GAAP operating income, non-GAAP operating margin, and free cash flow. NVIDIA believes the presentation of its non-GAAP financial measures enhances investors' overall understanding of the company's historical financial performance. The presentation of the company's non-GAAP financial measures is not meant to be considered in isolation or as a substitute for the company's financial results prepared in accordance with GAAP, and the company's non-GAAP measures may be different from non-GAAP measures used by other companies. Further information relevant to the interpretation of non-GAAP financial measures, and reconciliations of these non-GAAP financial measures to the most comparable GAAP measures, may be found in the slide titled “Reconciliation of Non-GAAP to GAAP Financial Measures”. NVIDIA’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined computer graphics, revolutionized accelerated computing, ignited the era of modern AI, and is fueling industrial digitalization across markets. Today, two transitions are occurring simultaneously—accelerated computing and generative AI—transforming the computer industry and every other industry worldwide, and NVIDIA is enabling these transitions with our full-stack computing platform and data-center-scale offerings. NVIDIA’s platform is installed in several hundred million computers, is available in every cloud and from every server maker, powers over 75% of the TOP500 supercomputers, and has close to 5.5 million developers. NVIDIA Headquarters: Santa Clara, CA | Headcount: 30,000+ NVIDIA released GeForce 256, the world’s first GPU, 25 years ago. This marked a milestone in computing by providing gamers with higher frame rates, smoother gameplay, and life-like graphics. NVIDIA's GPU set the foundation for the big bang of modern AI, a decade later. The parallel processing power of NVIDIA GPUs and the invention of a revolutionary programming model “CUDA” attracted researchers who recognized the opportunity to accelerate computationally-demanding applications like physical and chemical simulations and deep learning.NVIDIA released the GeForce RTX series in 2018, reinventing computer graphics once again with real-time ray tracing and neural rendering, applying AI to generate pixels at quality and speed no one thought possible.Today, the world recognizes GPUs not only for reshaping gaming but also for powering the AI industrial revolution. NVIDIA GeForce 256 started an era where gaming, computing, and AI evolve together, fundamentally advancing entertainment, technology, and society. World’s First GPU Turns 25 NVIDIA Scaling with AI Scale-Up and Scale-OutNVIDIA’s chips and systems supply chain expanded significantly in 2024, while demand continues to exceed supply.NVIDIA Blackwell platform in full production – expanding to support x86 and NVIDIA Grace, air and liquid cooling, NVLink 8-GPU to NVLink 72-GPU, InfiniBand and Ethernet, CSP, regional AI factories, and enterprise platforms.One Year Rhythm at full infrastructure scale.AI training continues AI scaling law. OpenAI o1 starts inference-time scaling law. Inference is driving significant workload growth and demand.Regional and sovereign clouds start up around the world.NVIDIA AI Enterprise and Omniverse set the foundations for enterprise and industrial AI. GPU-AcceleratedData Centers AI Factories General-PurposeComputing AI AcceleratedComputing TraditionalData Centers Accelerated Computing and Generative AI Create Trillion-dollar OpportunitiesThe $1T installed base of general-purpose CPU data center infrastructure isbeing modernized to a new GPU accelerated computing paradigm. The entire computing stack has been reinvented – from CPU to GPU, from coding to machine learning, from software to generative AI. Computers generate intelligence tokens, a new commodity.A new type of data center, AI Factories, isexpanding the data center footprint to $2T and beyond in the coming years. Eventually,companies in every industry will operate AI factories as the digital twin of their workforce, manufacturing plants, and products. A new industrial revolution has begun. AI Factories—A New Class of Data Centers AI factories are a new form of computing infrastructure. Its purpose is not to store user and company data or run ERP andCRM applications. AI factories are highly optimized systems purpose-built to process raw data, refine it into models, and produce monetizable tokens with great scale and efficiency.In the AI industrial revolution, data is the raw material, tokens are the new commodity, and NVIDIA is the token generator in the AI factory.Every company will produce digital intelligence. Tokens will be transformed into intelligent responses and actions of digital nurses, tutors,customer service agents, and chip designers, manufacturing robots and autonomous cars, andweather prediction agents to warn us of storms. Some companies will build and operate AI factories, while others willrent. Countries are awakening to the need to treat its data as a national resource and AI factories as an essential national infrastructure. Data encodes a nation's history, knowledge, and culture, and can be transformed into the sovereign AI for its companies, startups, universities and governments.NVIDIA builds the complete AI system and licenses NVIDIA AI Enterprise, the AI stack and operating systemfor AI factories. Production of digital intelligence tokens Data Tokens AI Factory NVIDIA’s Accelerated Computing PlatformData center scale innovation across chips, networking, systems, software, and algorithmsNVIDIA has accelerated software and compute by a 1,000,000X in the last decade, far surpassing Moore’s law.Accelerated computing requires full-stack innovation—optimizing across every layer of computing—from chips and systems to software and algorithms, demanding deep understanding of the problem domain.Our platform extends from the cloud and enterprise data centers to supercomputing, edge computing, PCs, and robotics. CUDA-XLibraries Accelerated Software Stack NeMoCUDA-AcceleratedAgentic AI LibrariesOmniverseCUDA-AcceleratedPhysical AI Libraries Chips Purpose-Built for AI SupercomputingGPU | CPU | DPU | NIC | NVLINK Switch | IB Switch | ENET Switch NVLINKSwitch & SpineGB200 NVL72SuperPOD Quantum & SpectrumSwitchGrace BlackwellMGX-Node BlackwellHGX-Node CUDA • DOCA • NCCLCluster-Scale SoftwareSystem SoftwareChip Software NVLink Switch NIM CUDA-Accelerated “All in-a-Container” Transceivers & Cables Extending NVIDIA Networking to Scale-Up and Scale-Out AI in Any DatacenterNew NVLink and Spectrum-X Increase Networking Opportunity Beyond InfiniBand to Every Data Center Generative AI is a Data Center-Scale Computing WorkloadLimitless Scaling with NVLINK + InfiniBand or Spectrum-X NVIDIA NVLinkFastest Interconnect for GPU Scale-Up NVIDIA InfiniBandSupercomputing and Dedicated AI Factories NVIDIA Spectrum-XEthernet Optimized for Multi-Tenant AI Factories # of GPU in a Data Center NVIDIA Spectrum-X AI Ethernet Fabric 101001k 100k10k 1M+ AI PerformanceInfiniBand NVLink +InfiniBand / Spectrum-X Traditional Ethernet Accelerated Computing Starts with CUDA Libraries Unlike CPU general-purpose computing, GPU-accelerated computing requires software and algorithms to be re-designed. Software is not automatically accelerated in the presence of a GPU or accelerator.NVIDIA CUDA libraries encapsulate NVIDIA-engineered algorithms that enable applications to be accelerated on NVIDIA’s installed base. They deliver dramatically higher performance—compared to CPU-only alternatives—across application domains, including AI and high-performance computing significantly reducing run time, cost, energy, while increasing scale.With over 400 CUDA libraires NVIDIA can address many major workloads across a wide range of industries. As new libraries become available, they unlock new markets adding to our long-term opportunity. Delivering up to 200X Speedup Across Major Workloads Speech AIRiva, TensorRT, Triton Inference Server, NeMo, cuBLAS, cuDNN, cuFFT, CUTLASS~30X Recommender SystemsMerlin, HugeCTR, TensorRT, Triton Inference Server, cuBLAS, cuDNN, cuFFT, cuSPARSE, CUTLASS, Magnum IO, NCCL, cuVS~50X Deep LearningcuDNN, CUTLASS, Megatron, TensorRT, TRT LLM, NCCL, NV-Triton, CUDA-optimized PyTorch, Tensorflow, Triton, Jax~100X ScienceEarth-2 CorrDiff, Holoscan, Parabricks, Monai, Modulus, Warp, cuLitho, cuQuantum, CUDA-Q, AmgX, cuDSS, cuFFT, cuSOLVER, cuBLAS, cuSPARSE, cuTENSOR, cuGraph, Magnum IO, NCCL, NVSHMEM, RAFT, cuNumeric, Sionna~100X Agentic & Physical AIACE, Riva, Nemo, Tokkio Digital Human,Holoscan, Metropolis, Omniverse, Isaac, DRIVE, cuLitho, cuMotion, cuOpt, Aerial CUDA-accelerated RAN, Sionna, fVDB, PhysX, Warp, NVblox~100X Computer VisionCV-CUDA, Deepstream, TAO, Holoscan, cuCIM, TensorRT, Triton Inference Server, DALI, nvImageCodec, cuDNN, nvJPEG, nvJPEG2000, nvTIFF, NPP, Video Codec SDK, Magnum IO, NCCL, cuVS, DALI~200X Data ProcessingcuVS, cuDF-Spark, cuDF-pandas, cuDF-Polars, cuGraph, cuML, XGBoost, RAPIDS,NeMo Curator, cuSOLVER, cuIO~200X Accelerated Computing Is Sustainable Computing Accelerated computing requires higher peak power consumption than CPUs, however, completes workloads significantly faster and consumes less total energy Time(sec) Server TDP (kW) Kepler42000 Joules/Token Pascal17640 J/Token Volta1200 J/TokenAmpere150 J/TokenHopper10 J/TokenBlackwell0.4 J/Token2014 2024 Order-of-Magnitude More Energy-Efficient Accelerated computing enables full-stack optimization from algorithm to GPU architecture, such as Tensor Core Transformer Engine;LLM energy-efficiency improved 100,000X in the past 10 yearsGPT-MoE-1.8T energy per tokenEnergy Usage in AI Inference CPUNVIDIA 12 AI Scaling Laws Drive Exponential Demand for ComputeNew OpenAI o1 Long “Thinking Time” Creates a New Way to Scale Inference compute scales exponentially with larger models, multi-modality, large context, low latency, and nowlong “thinking time” Training compute scales exponentially with larger models, multi-modality, reinforcement learning, and synthetic data generationTrainingCompute InferenceCompute o1 13 NVIDIA is the Leading Inference PlatformInference ComputeScales Exponentially with “Long Thinking” Flash AttentionKVCache PageAttentionDistillationPruning & QuantizationNeural Architecture SearchDisaggregated ServingSpeculative DecodingMulti-GPU, Multi-Node GB200 NVL72NVLink Switches130 TB/s All-to-All BWOne Giant Blackwell1.44 EF FP4576TB/s HBM3e Hopper inference performanceincreased 5X in 1 Yearwith rapidalgorithm innovationsenabled by rich NVIDIA CUDA ecosystemInstalled base & CUDA ➔ rapid softwareinnovation ➔ performance ➔ lower inference cost ➔increase demand ➔ increase installed baseInference compute scaling exponentially with large multi-modal models, Chain-of-Thought, reasoning, agents, and low latency responses NVIDIA AI Infrastructure Roadmap at One Year Rhythm NVIDIA’s newest architecture – Blackwell – is an AI infrastructure platform and integrates seven chips, each contributing to performance at data center-scale.Compute demand for AI is scaling exponentially. Model size, multi-modality, synthetic data generation and reinforcement learning is scaling computing capacity by ~4x per year. And new inference-time technologies like multi-modality, Chain-of-Thought, reasoning, and agents have introduced an exponential scaling law to inference.NVIDIA has the scale and ability to update the entire AI infrastructure on a One Year Rhythm as we can engineer and optimize across the full stack and the entire infrastructure. The cadence and breadth of our innovation brings more performant AI infrastructure to the market each year, delivering exceptional TCO, energy efficiency, and ROI to our customers. One Year Rhythm | Supercluster Scale | Full-Stack | CUDA Everywhere“Supercharge AI Scaling Law” Rubin Blackwell Hopper Blackwell-Ultra Blackwell Ultra GPU288GB HBM3eMore AI FLOPS NVLink Switch900 GB/sec CX7 SuperNIC Hopper GPU6S HBM3Hopper+ GPU6S HBM3e BF3 SuperNIC Quantum-X400Infiniband Switch Spectrum Ultra X800Ethernet Switch 512-Radix Grace CPU NVLink 6 Switch3600 GB/sec CX9 SuperNIC1600 Gb/sec Rubin GPU8S HBM4 Vera CPU X1600IB/Ethernet Switch Rubin GPU12S HBM4 2022 2024 20262023 2025 2027 X-FactorsX-Factors X-Factors CX8 SuperNIC One Year Rhythm Drives Annual Cost and Energy ReductionSignificant reduction in TCO with each generation Hopper | 8,000 GPUs | 15MWBlackwell GB200 NVL72 | 2,000 GPUs | 4MW LLM Training Workload: GPT-MoE-1.8T | Train in 90 days | H100 vs GB200 NVL72 4XReduction in Power 17 NVIDIA NVLink Enables New Level of AI Training & Inference Scaling GB200 NVL72NVLink Switches130 TB/s All-to-All BWOne Giant Blackwell1.44 EF FP4576TB/s HBM3e NVLink Switch NVIDIA Addresses The Entire AI MarketNVIDIA’s accelerated computing platform encompasses a complete computing stack andinfrastructure required for customers to build and run AI at scale.CUDA-X libraries and microservices leverage the programmability of CUDA to enable thousands of applications across a wide range of use cases to run on NVIDIA infrastructure, including AI training and inference, data processing, robotics, drug discovery, and consumer internet services.NVIDIA has a rich ecosystem of partners who have integrated NVIDIA platform technologies and joined our go-to-market. Each industry and market segment may include different domain-specific software stacks, ODMs, OEMs, CSPs, 3rd party software platforms, system integrators, and system integrations/solution development partners.The completeness of the NVIDIA platform for each industry and workload lets us address every industry from healthcare, manufacturing, and transportation to retail, CSPs, and telecommunications. NVIDIA AI Platform and Ecosystem Reaches Every Market DataPre-ProcessingTrainingPostTraininge.g., SDGAgentic AIInferenceRobotic AIInference AI Infrastructure Software AI Technology EcosystemEvery CloudOEMs&ODMs PC & WorkstationsEdge & Robotics Full-StackCompute-to-Networking Full-Stack, Entire AI InfrastructureEvery Workload toAddress the World'sIndustriesAccelerate Every Workload Sovereign AI Regional CSP Telcos InternetServicesPublicCloud HeavyIndustries EnterprisesAuto, Healthcare, Logistics, Energy, FSI, etc. AIStartups SaaSSocial Media Platforms AI Driving Investment Cycle and Significant Returns AI Agents, or copilots and AI teammates, automate tasks at superhuman speed, increase employee productivity and accelerate businesses. Agents can generate documents, review contracts, help code and debug software, operationalize marketing campaigns, andreview medical images Social media, search and e-commerce apps are using deep recommenders to offer more relevant content and generative AI to hyper-customize ads to their customers, increasing engagement and monetizationCreators can generate stunning, photorealistic images or 3D objects with a single text prompt—compressing workflows that take days or weeks into minutes in industries from advertising to game developmentCall center agents augmented with AI chatbots can scale to deliver customer care during peak times, run in-the-loop with customer support to provide better service, and capture every interaction to build institutional knowledge in high turnover industriesDrug discovery is seeing order-of-magnitude workflow acceleration using generative AI for candidate drug generation and target selectionManufacturing is using generative AI to generate ideas to inspire designers, accelerate the planning and layout of factories and warehouses; andfor self-learning robots that can handle diverse tasksin changing work environmentsClimate Tech scientists are using AI to discover new materials for better batteries, emulate complex physics to predict long-range weather, estimate carbon-capture sites, optimize wind farm output AI is accelerating scientific discovery, creativity, and productivity across industries Source: Goldman Sachs, Cowen, Statista, Capital One, Wall Street Journal, Resource Watch, NVIDIA internal analysis AI Agents & CopilotsOver 1B knowledge workersSearch & Social Media$700B in digital advertising annuallyAI Content Creation50M creators globally Legal Services, Education 1M legal professionals in the US9M educators in the US AI Software Development30M software developers globally Financial Services678B annual credit card transactions Customer Service 15M call center agents globallyDrug Discovery1018 molecules in chemical space40 exabytes of genome dataManufacturing$50T of Heavy Industry The Enterprise and Industrial AI Wave of Adoption Has StartedAI brings computinginto the core of the $100T global industries. Companies will leverage AI to unlock new monetizable applications, enhance employee productivity, and transform their business models.NVIDIA AI Enterprise platform, which includes NVIDIA NeMo agent on-boarding and operating software platform, NVIDIA NIM “model-in-a-container” microservices, and AI Foundry custom-AI service, enables enterprises to build and run custom agentic AI applications.Industrial AI applications will serve large markets – including 10M factories, 200K warehouses, billions of humanoid robots, and 100M autos manufactured each year. NVIDIA Omniverse provides a platform for building and deploying autonomous machine applications. Omniverse connects to leading design, simulation, and factory control software and enables virtual integration of factories and warehouses into operational digital twins. This is Mayfield’s webpage of AI companies in their portfolio. The illustration and description provide a framework of enterprise AI – agents are a new digital workforce that will collaborate and accelerate the work of employees.Specialized AI co-pilots, teammates, or agents will collaborate with employees, be given access to necessary data, use platform tools like SAP, Snowflake, or ServiceNow, and even collaborate with other AI agents.In time, the world’s companies will hire billions of AI agents in its workforce.NVIDIA AI Enterprise offers the IT and services ecosystem, NVIDIA-optimized NeMo agent lifecycle libraries, NIM pre-trained models, and DGX Cloud infrastructure to build and deploy enterprise AI.Enterprises license NVIDIA AI Enterpriseat $4500 per-GPU per-Year to run NIM and NeMo libraries. Enterprise AI Wave is HereCo-Pilots, AI Teammates, and Agents are the New Digital Workforce to Revolution Enterprise Productivity NVIDIA AI Enterprise Enables IT Ecosystem with State-of-the-ArtAI Models and Libraries to Build Agentic AI Database NVIDIA NeMo RetrieverVector Database NVIDIA NeMo NVIDIA NIM DataFlywheel User Action . . . . . . NVIDIA AI Enterprise Ecosystem System Integrators Enterprise ISVs Data Platforms Cloud and On-Prem Infrastructure . . . . . . AI Agent 24 NVIDIA Omniverse and AI Revolutionizing Manufacturing & Robotics 10M Factories 200K Warehouses 100M Cars Billions in Future The next AI wave is physical AI - models that can perceive, understand, and interact with the physical world. Physical AI will embody robotic systems – from autonomous vehicles to industrial robots and humanoids, to warehouses and factories.Three computers and software stacks are required to build physical AI: NVIDIA AI on DGX to train the AI model, NVIDIA Omniverse on OVX to teach, test, and validate the AI model's skills, and NVIDIA AGX to run the AI software on the robot.Enterprises license NVIDIA Omniverse at $4500 per-GPU per-Year. 25 Sovereign AI JapanNational Institute of Advanced Industrial Science and Technology (AIST) SwitzerlandSwisscom Group EcuadorTelconet SingaporeSingapore Telecommunications Limited (Singtel) SpainBarcelona Supercomputing Center FranceScaleway VietnamFPT Smart Cloud Location of NVIDIA Sovereign AI partners Sovereign AINations are awakening to the imperative to produce artificial intelligence using their own infrastructure, data, workforces and business networks. Nations are building domestic computing capacity. Some governments operate sovereign AI clouds in collaboration with state-owned telecommunications providers or utilities. Other governments partner with local cloud providers to deliver a shared AI computing infrastructure for public- and private-sector use.NVIDIA’s ability to help build AI infrastructure with our end-to-end compute-to-networking technologies, full-stack software, AI expertise, and rich ecosystem of partners and customers allows sovereign AI and regional cloud providers to jumpstart their countries’ AI ambitions. Nations produce AI using their own data, infrastructure, workforce, and business networks $10,918$16,675$26,914$26,974 $56,084$60,922 FY20FY21FY22FY23FY24H1 FY25 Driving Strong and Profitable Growth Revenue ($M) $3,735$6,803$12,690$9,040 $37,134$37,997 34%41%47%34% 61%68% FY20FY21FY22FY23FY24H1 FY25 Fiscal year ends in January. Refer to Appendix for reconciliation of Non-GAAP measures. Operating margins rounded to the nearest percent. Operating Income ($M)Operating Margin % Non-GAAP $4.3B$4.7B$8.0B $3.8B $26.9B$28.4B FY20FY21FY22FY23FY24H1 FY25 Strong Cash Flow Generation Fiscal year ends in January. Refer to Appendix for reconciliation of Non-GAAP measures. 1 Subject to continuing determination by our Board of Directors. Free Cash Flow (Non-GAAP) Capital AllocationShare Repurchase•Utilized $14.9B of cash for repurchases in H1 FY25•Additional $50B in stock repurchase authorization, adding to $7.5B which remained as of the end of Q2Dividend•$344M in H1 FY25•Dividend increased by 150% in Q2 FY25•Plan to Maintain1 Strategic Investments•Growing Our Talent •Platform Reach & Ecosystem DGX/HGX/MGX/IGX systemsGPU | CPU | DPU | NetworkingNVIDIA AI software Our Market Platforms at a Glance FY24 Revenue $47.5B5-YR CAGR 75%FY24 Revenue $10.4B5-YR CAGR 11%FY24 Revenue $1.6B5-YR CAGR 7%FY24 Revenue $1.1B5-YR CAGR 11%GeForce GPUs for PC gamingGeForce NOW cloud gamingDRIVE Hyperion sensor architecture with AGX computeDRIVE AV & IX full stack software for ADAS, AV & AI cockpit NVIDIA RTX GPUs for workstationsOmniverse software Professional VisualizationAutomotive17% of FY24 Revenue3% of FY24 Revenue2% of FY24 Revenue Data Center78% of FY24 RevenueGaming 29 Reconciliation of Non-GAAP to GAAP Financial Measures Reconciliation of Non-GAAP to GAAP Financial MeasuresOperating Income and Margin($ in Millions & Margin Percentage)Non-GAAPAcquisition Termination CostAcquisition-Relatedand Other Costs (A)Stock-Based Compensation (B)Other(C)GAAP FY 2020$3,735— (31)(844)(14)$2,84634.2%— (0.3)(7.7)(0.1)26.1% FY 2021$6,803— (836)(1,397)(38)$4,53240.8%— (5.0)(8.4)(0.2)27.2% FY 2022$12,690— (636)(2,004)(9)$10,04147.2%— (2.5)(7.4)— 37.3% FY 2023$9,040(1,353)(674)(2,710)(79)$4,22433.5%(5.0)(2.5)(10.0)(0.3)15.7% FY 2024$37,134— (583)(3,549)(30)$32,97261.0%— (1.0)(5.8)(0.1)54.1% H1 FY 2024$10,828— (311)(1,576)— $8,94152.3%— (1.5)(7.6)— 43.2% H1 FY 2025$37,997— (286)(2,164)4 $35,55167.8%— (0.5)(3.9)— 63.4% A.Consists of amortization of acquisition-related intangible assets, inventory step-up, transaction costs, compensation charges, and other costsB.Stock-based compensation charge was allocated to cost of goods sold, research and development expense, and sales, general and administrative expenseC.Comprises of legal settlement cost, contributions, restructuring costs and assets held for sale related adjustments Reconciliation of Non-GAAP to GAAP Financial Measures($ in Millions)Free Cash FlowPurchases Related to Property and Equipment and Intangible AssetsPrincipal Payments on Property and Equipment and Intangible AssetsNet Cash Provided by Operating Activities FY 2020$4,272 489 — $4,761 FY 2021$4,6771,128 17 $5,822 FY 2022$8,049 976 83 $9,108 FY 2023$3,7501,833 58 $5,641 FY 2024$26,9471,069 74 $28,090 H1 FY 2024$8,691 537 31 $9,259 H1 FY 2025$28,4181,346 69 $29,833 32