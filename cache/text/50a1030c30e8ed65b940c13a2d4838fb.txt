“Everything Everywhere All at Once” AI Scales Beyond LLMs Nemotron Agentic AI Cosmos Physical AI GR00T Robotics Alpamayo Autonomous Vehicles Clara Biomedical AI Earth-2 AI-Physics NVIDIA Leads Open Model Ecosystem Language Models Released in 2025 Source: Hugging Face Count excludes quantized models, but includes variants (e.g., reasoning vs. instruct) and fine-tunes of other models 0 25 50 75 100 Google IBM Granite AI2 Microsoft Mistral Z.ai DeepSeek Kimi Minimax Meta Llama OpenAI Alibaba Qwen NVIDIA Generate and Process Data Model Building Train and Customize Evaluate Research Guardrail & Deploy NVIDIA Tops Leaderboards Artificial Analysis Intelligence Index Artificial Analysis Intelligence per Token VLM3D OpenASR Physical Reasoning MVPBench, IntPHys, CasualVQA OCRBench Retrieval ViDoRe, MTEB, MMTEB Physical AI PAIBench Agents Are Multi-Model, Multi-Cloud, and Hybrid-Cloud App, Data Platforms (MCP) Filesystem Semantic Search Web Search User or Machine Tool Use Prompt Response Critique Plan Sandbox Reason Memory Agents Are Multi-Model, Multi-Cloud, and Hybrid-Cloud App, Data Platforms (MCP) Filesystem Semantic Search Web Search User or Machine Tool Use Prompt Response Critique Plan Sandbox Reason Memory Frontier Models Router Customized Open Models Edge Video Analytics Accelerated Data Science and ML IT and HR Workflow Automation Enterprise Platforms Adopt NVIDIA AI Code Review Real-Time Security Analyst Enterprise Platforms Adopt NVIDIA AI Retrieval Augmented Generation NVIDIA Full-Stack Physical AI Platform Cosmos Compute is Data Announcing NVIDIA Alpamayo Driving Decision Trajectory Multi-Camera Video Ego-Motion History Causal Reasoning Optional User Commands Alpamayo Open Reasoning VLA for Autonomous Vehicles “Parked cars mean the ego needs to be cautious of sudden movements” “Ball rolling could be a hazard-maybe a child or pet following it” “Slow down and prepare to stop if the ball or pedestrians pose a risk” Alpamayo Announcing NVIDIA Alpamayo Open Reasoning VLA for Autonomous Vehicles Halos Safety OS Classical AV Stack Alpamayo Policy and Safety Evaluator NVIDIA Ships Full-Stack AV on 2025 Mercedes Benz CLA Global L4 and Robotaxi Ecosystem Building on NVIDIA Tier 1 and Hardware Partners OEMs and Mobility Platforms AV Software Agentic AI Optimization AI Silicon Agent Systems Agent Cadence JedAI Platform Cadence Cerebrus® Digital Virtuoso® Studio Custom Verisium Verification Allegro® X AI PCB/Package Optimality System Vendor LLM Customer Vendor RAG Customer Principled Simulation & Optimization System Design Automation Sciences Virtuoso Custom Spectre® X … Xcelium Verification Jasper® … Innovus Digital & Signoff Voltus Celsius … Allegro Package & PCB Allegro APD … Cadence Reality Data Center … Orion Molecular … Fidelity® System Clarity … Beta CAE Accelerated Computing 3rd Party CSP Compute Customer Farm Knowledge Sources 3rd Party Hardware Emulation Palladium® Software and System Protium AI Supercomputer Millennium X86 CPU GPU Arm® CPU DPU FPGA Cadence IP This slide contains forward-looking statements regarding Cadence's business or products. Actual results may differ materially from the information presented here. Electronic Design Automation Electronic Design Automation Structures Fluids Electronics, Electromagnetics OpticsDesign Manufacturing Verification PrimeLib Redhawk-SC Totem SC Proteus S-Litho S-Device Quantum ATK PrimeSim VCS Mechanical LS-Dyna Discovery Fluent FreeFlow Rocky HFSS Icepak Maxwell SPEOS Zemax Lumerical FDTD Semiconductor DT Industrial DT Medical DT Aerospace DT Robotics DT Automotive DT Computer Aided Engineering Physical AI Synopsys AgentEngineerTM Technology Targeting Availability in Every Cloud and OEM NVIDIA Omniverse In production Legend Powered by Siemens Xcelerator Industries Chip Design Design / Engineering Operations Fuse Solido Calibre Tessent Questa One Veloce Aprisa Industrial AI Suite Industrial Edge Infrastructure BuildingX Gridscale X Electrification X Catapult Xpedition HyperLynx Totally Integrated Automation (TIA) Industrial Cybersecurity Services Teamcenter Digital Reality Viewer Designcenter Simcenter Digital Twin Opcenter Nemotron Agentic AI Cosmos Physical AI GR00T Robotics Alpamayo Autonomous Vehicles Clara Biomedical AI Earth-2 AI-Physics NVIDIA Leads Open Model Ecosystem Language Models Released in 2025 Source: Hugging Face Count excludes quantized models, but includes variants (e.g., reasoning vs. instruct) and fine-tunes of other models 0 25 50 75 100 Google IBM Granite AI2 Microsoft Mistral Z.ai DeepSeek Kimi Minimax Meta Llama OpenAI Alibaba Qwen NVIDIA Generate and Process Data Model Building Train and Customize Evaluate Research Guardrail & Deploy Vera Rubin Test-Time Scaling “Thinking” 5X Tokens Per Year Token Cost 10X Cheaper Per Year Model Size Growing 10X Parameters Per Year Llama-13B Kimi-K2 1T Mixtral 8x22B Llama-2 70B GPT-Neo 1.3B PaLM-2 Qwen-72B Qwen3-480B 2023 2024 2025 1,000 100 10 1 0.1 2021 2023 2025 100,000 10,000 1,000 100 CLIP-ViT (86M) Reasoning Non-Reasoning Source : EPOCH AI Source : Artificial Analysis Insane Demand for AI Computing GPT-3.5 GPT-3.5 Turbo Llama 3 8B Llama 3.1 8B Llama 3.1 8B GPT-4 GPT-4 Turbo GPT-4o Llama 3.1 70B Llama 4 Maverick $0.01 $0.10 $1.00 $10.00 $100.00 2022 2024 2025 88 NVIDIA Custom Olympus Cores 176 Threads with NVIDIA Spatial Multi-Threading 1.8 TB/s NVLink-C2C 1.5 TB System Memory (3X Grace) 1.2 TB/s LPDDR5X 227 Billion Transistors NVIDIA Vera CPU NVFP4 Inference 50 PFLOPS 5X Blackwell NVFP4 Training 35 PFLOPS 3.5X HBM4 Bandwidth 22 TB/s 2.8X NVLink Bandwidth per GPU 3.6 TB/s 2X Transistors 336 Billion 1.6X NVIDIA Rubin GPU 800 Gb/s Ethernet with 200G PAM4 SerDes Programmable RDMA and Data Path Accelerator State-of-the-Art Security Line-Speed Encryption | Security Enclave and Attestation CNSA and FIPS Certified 23 Billion Transistors NVIDIA ConnectX-9 Spectrum-X SuperNIC 800G Gb/s DPU for SmartNIC and Storage Processor 64 Core Grace CPU with ConnectX-9 126 Billion Transistors NVIDIA BlueField-4 6X Compute 3X Memory BW vs BF3 2X Networking Scale-Up Fabric with 3.6 TB/s Per-GPU All-to-All BW 400G SerDes In-Network SHARP Collectives 108 Billion Transistors NVIDIA NVLink 6 Switch NVIDIA Vera Rubin NVL72 NVFP4 Inference 3.6 EFLOPS 5X Blackwell NVFP4 Training 2.5 EFLOPS 3.5X LPDDR5X Capacity 54 TB 3X HBM Capacity 20.7 TB 1.5X HBM4 Bandwidth 1.6 PB/s 2.8X Scale-Up Bandwidth 260 TB/s 2X Transistors 220 Trillion 1.7X 102.4 Tb/s Scale-Out Switch Infrastructure Co-Packaged 200G Silicon Photonics 128 Ports of 800 Gb/s 512 Ports of 200 Gb/s 352 Billion Transistors NVIDIA Spectrum-X Ethernet Co-Packaged Optics Context is the New Bottleneck – Storage Must be Rearchitected Model Size Growing Context Length Growing Multi-Turn Conversations - Context Accumulates More Concurrent Users and Sessions HBM Memory Rack SSD Network SSD NVIDIA Context Memory Storage Platform A New POD-Level Context Memory Platform ​ ​BlueField-4 Data and Storage Processor Spectrum-X Ethernet RDMA Infrastructure 5X Higher Tokens per Second 5X Higher Power Efficiency Vera Rubin Six New Chips – One Giant Leap to the Next Frontier 4K 64K 128K $6.00 $2.00 $0.00 Six New Chips – One Giant Leap to the Next Frontier Kimi K2-Thinking (32K/8K) Kimi K2-Thinking (32K/8K)DeepSeek++ 32K 96K 50 150 450250 350 25 35 4020 30 Factory Throughput Up to 10X More Tokens Token Cost 1/10th Lower Cost Time to Train 1/4th Fewer GPUs TPS/User (Interactivity) Latency (s)Number of GPUs Rubin NVL72Blackwell NVL72 5M 4M 3M 0 2M 1M $8.00 $4.00 $10.00 Throughput 100T Tokens in 1 Month NVIDIA One Platform for Every AI Vera Rubin Open Models Alpamayo Isaac Agentic AI