AlexNet VGG-19 Seq2Seq Resnet InceptionV3 Xception ResNeXt DenseNet201 ELMo MoCo ResNet50 Wav2Vec 2.0 Transformer GPT-1 BERT Large GPT-2 1.5B XLNet Megatron-NLG Microsoft T-NLG GPT3-175B MT NLG 530B BLOOM Chinchilla PaLM GPT-MoE-1.8T 2012 2014 2016 2018 2020 2022 2024 Training Compute (petaFLOPs) Training Compute PFLOPs 102 103 104 105 106 107 108 109 1010 SELENE 2021 4,480 A100 GPUs 3 EF AI Compute 112 TB/s Interconnect BW EOS 2023 10,752 H100 GPUs 43 EF AI Compute 1,100 TB/s Interconnect BW ANNOUNCING NVIDIA BLACKWELL PLATFORM FOR TRILLION-PARAMETER SCALE GENERATIVE AI DECOMPRESSION ENGINE 800 GB/sec 2nd GEN TRANSFORMER ENGINE FP4/FP6 Tensor Core AI SUPERCHIP 208B Transistors 5th GENERATION NVLINK Scales to 576 GPUs SECURE AI Full Performance Encryption & TEE RAS ENGINE 100% In-System Self-Test Blackwell GPU FP8 20 PFLOPS 2.5X Hopper NEW FP6 20 PFLOPS 2.5X NEW FP4 40 PFLOPS 5X HBM Model Size 740B param 6X HBM Bandwidth 34T param/sec 5X NVLINK All-Reduce with SHARP 7.2 TB/s 4X 2016 2017 2020 2022 2024 TFLOPS Pascal 19 TFLOPS FP16 Volta 130 TFLOPS FP16 Ampere 620 TFLOPS BF16/FP16 Blackwell 20,000 TFLOPS FP4 Hopper 4,000 TFLOPS FP8 1000X AI Compute in 8 Years NVLink Switch Chip 50B Transistors in TSMC 4NP 72-Ports Dual 200 Gb/sec SerDes 4 NVLinks at 1.8TB/sec 7.2TB/sec Full-Duplex Bandwidth SHARP In-Network Compute – 3.6 TFLOPS FP8 Training FP8 720 PFLOPS 22X Inference FP4 1.44 ExaFLOPS 45X Multi-Node All-to-All 130 TB/sec 18X Multi-Node All-Reduce 260 TB/sec 36X DGX GB200 NVL72 1 Giant GPU LLM Training Workload: GPT-MoE-1.8T | H100 vs GB200 NVL72 Train GPT-MoE-1.8T in 90 Days Hopper 8000 GPUs | 15MW LLM Training Workload: GPT-MoE-1.8T | H100 vs GB200 NVL72 Train GPT-MoE-1.8T in 90 Days Blackwell GB200 NVL72 2000 GPUs | 4MW 1/4th the Power 0 20 40 60 80 100 120 140 160 0 10 20 30 40 50 TP4.EP16 TP2.EP16.PP2 TP2.EP8.DP4 0 20 40 60 80 100 120 140 160 0 10 20 30 40 50 Throughput per GPU Tokens per Second Multi-Dimensional Optimization: • Tensor Parallel • Pipeline Parallel • Expert Parallel • Data Parallel GB200 FP4 Interactivity per User Tokens per Second GPT-MoE 1.8T Inference (seqlen=32k/1k, FTL=5s) TP64 TP8.PP4.DP2 TP64 TP8.PP2.DP4 TP4.EP2.PP2.DP4 TP4.EP16 TP2.EP16.PP2 TP2.EP8.DP4 0 20 40 60 80 100 120 140 160 0 10 20 30 40 50 Blackwell 30X Hopper Throughput per GPU Tokens per Second Interactivity per User Tokens per Second GB200 FP4 B200 FP8 H200 FP8 Multi-Dimensional Optimization: • Tensor Parallel • Pipeline Parallel • Expert Parallel • Data Parallel GPT-MoE 1.8T Inference (seqlen=32k/1k, FTL=5s) “CAT” TEXT SOUND TEXT TEXT IMAGE VIDEO SPEECH MULTI-MODAL AMINO ACID BRAINWAVES SPEECH IMAGE VIDEO IMAGE 3D ANIMATION MANIPULATION PROTEIN LEARN AND UNDERSTAND EVERYTHING NVIDIA HEALTHCARE BIOINFORMATICSGENOMICS DRUG DISCOVERYIMAGING & ROBOTICS MONAI | Holoscan Parabricks RAPIDS BioNeMo User Optimized Molecules Protein Database DiffDock AlphaFold2 MolMIM UniDock Gradient-Free Optimization NVIDIA INFERENCE MICROSERVICE Pre-Trained AI Models Packaged and Optimized to Run Across CUDA Installed Base NVIDIA CUDA Cloud Native Stack GPU Operator, Network Operator Triton Inference Server cuDF, CV-CUDA, DALI, NCCL, Post Processing Decoder Enterprise Management Health Check, Identity, Metrics, Monitoring, Secrets Management Kubernetes Industry Standard APIs Text, Speech, Image, Video, 3D, Biology Customization Cache P-Tuning, LORA, Model Weights Optimized Model Single GPU, Multi-GPU, Multi-Node TensorRT LLM and Triton cuBLAS , cuDNN, In-Flight Batching, Memory Optimization, FP8 Quantization 100’s of Millions of CUDA GPUs Installed Base Prompt Event Knowledge Graph Other Agents Application Platform Application Platform Plan Structured Data (ERP, CRM) Vector Database Event Prompt Response NVIDIA ChipNeMo Llama 2 70B Before Fine-Tuning Event Prompt Response NVIDIA ChipNeMo Llama 2 70B With Fine-Tuning Fine-Tuning with P-Tuning, LoRA, SFT Alignment with RLHF, SteerLM Auto Scoring, Human Ratings, LLM-as-a-Judge Topical Content, Safety Security Rails NeMo Curator Microservice NeMo Customizer Microservice NeMo Evaluator Microservice NeMo Guardrails Microservice Foundation Model Domain, Complexity, Task Classification PII, Toxicity Redaction Deduplication Prompt Event Custom Model in NIM NeMo Microservices Retrieval Microservices Text-to-SQL Microservice RAPIDS cuVS Accelerated NN Search RAPIDS cuVS Accelerated Indexing Embedding Microservices Text PDF Docs Image Plan NeMo Retriever Vector Database Retrieval Microservices Text-to-SQL Microservice Plan Embedding Microservices Text PDF Docs Image RAPIDS cuVS Accelerated NN Search RAPIDS cuVS Accelerated Indexing NeMo Retriever Vector Database Chat with PDF Prompt Event Knowledge Graph Other Agents Application Platform Application Platform Plan Structured Data (ERP, CRM) Vector Database NVIDIA DHT DRIVE SIM IN OMNIVERSE OVX OMNIVERSE DIGITAL TWIN OVX ROBOTIC SYSTEM AGX DGX AI Occupancy APIs NVIDIA Omniverse Cloud NVIDIA DGX Cloud Omniverse Channel APIs USD APIs VLM APIs Worker Digital Twins Isaac Sim Isaac Sim Isaac Sim Warehouse Digital Twin AMR Robot Digital Twins cuOpt Sensor Fusion Route Planning Metropolis Metropolis cuOpt APIs Operator UI Application NVIDIA Omniverse Cloud Write | Render | Query | Notify Omniverse Channel APIsUSD APIs Edify 3D USD 360 HDRI Materials Prompt ChatUSD DeepSearch USD USD USD Data Lake Application NVIDIA Omniverse Cloud Omniverse Channel APIsUSD APIs Omniverse Channel APIs USD APIs NVIDIA Omniverse Cloud Apple Vision Pro NVIDIA Omniverse Cloud DRIVE THOR ASIL-D AV COMPUTER & STACK DRIVE SIM IN OMNIVERSE OVX DRIVE SIM IN OMNIVERSE DRIVE AV STACK MSFNET ROADNET PLANNET OVX AGX DGX NVIDIA Robotics Platform Adoption Robotics Developers 1.3M 100,000 ROS Developers 6,000 Companies Developing on Orin DRIVE SIM IN OMNIVERSE OVX ISAAC SIM IN OMNIVERSE ISAAC ROBOTIC STACK ISAAC PERCEPTOR OVX AGX DGX JETSON ORIN ROBOTIC COMPUTER & STACK DRIVE SIM IN OMNIVERSE OVX ISAAC SIM IN OMNIVERSE ISAAC MANIPULATOR STACK POSE GRASP MANIPULATE OVX AGX DGX JETSON ORIN ROBOTIC COMPUTER & STACK FoundationGrasp cuMotion SyntheticaDETR FoundationPose Language Videos Demonstrations Actions Observations Humanoid RobotGROOT Model DRIVE SIM IN OMNIVERSE OVX ISAAC LAB IN OMNIVERSE GR00T STACK GR00T FOUNDATION MODEL OVX AGX DGX JETSON THOR ROBOTIC COMPUTER & STACK A NEW INDUSTRIAL REVOLUTION NVIDIA Blackwell Platform GB200 Superchip Compute Node NVLINK Switch Quantum X800 Switch Spectrum X800 Switch BlueField-3 SuperNIC ConnectX-8 SuperNIC HGX B100