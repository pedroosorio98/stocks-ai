Responsible AI Transparency Report | Microsoft Skip to main content Microsoft Corporate Responsibility Corporate Responsibility Corporate Responsibility Home Featured AI Economy Institute Accelerating sustainability Cybersecurity Rural America Microsoft on the Issues Programs AI impact Communities Customer Security and Trust Digital skills Nonprofits and giving Sustainability Trusted technology Reports Reports Hub AI Diffusion Report Environmental Sustainability Report Microsoft Digital Defense Report Microsoft Impact Summary Responsible AI Transparency Report More All Microsoft Global Microsoft 365 Teams Copilot Windows Surface Xbox Deals Small Business Support Software Software Windows Apps Outlook OneDrive Microsoft Teams OneNote Microsoft Edge Moving from Skype to Teams PCs &amp; Devices PCs &amp; Devices Computers Shop Xbox Accessories VR &amp; mixed reality Certified Refurbished Trade-in for cash Entertainment Entertainment Xbox Game Pass Ultimate PC Game Pass Xbox games PC games Business Business Microsoft AI Microsoft Security Dynamics 365 Microsoft 365 for business Microsoft Power Platform Windows 365 Small Business Developer &amp; IT Developer &amp; IT Azure Microsoft Developer Microsoft Learn Support for AI marketplace apps Microsoft Tech Community Microsoft Marketplace Marketplace Rewards Visual Studio Other Other Microsoft Rewards Free downloads &amp; security Education Gift cards Licensing Unlocked stories View Sitemap Search Search or ask a question No results Cancel Sign in 2025 Responsible AI Transparency Report Share How we build, support our customers, and grow Our second annual Responsible AI Transparency Report covers the progress we’ve made since the publication of our inaugural report in 2024. It highlights our continued commitment to responsible innovation, covering how we develop and deploy AI models and systems responsibly; how we support our customers; and how we learn, evolve, and grow. View the 2025 report Key takeaways In 2024, we made key investments in our responsible AI tools, policies, and practices to move at the speed of AI innovation. Responsible AI tooling We improved our responsible AI tooling to expand coverage for risk evaluation and mitigations across modalities as well as for agentic systems. Approach to compliance We took a proactive, layered approach to compliance with new regulatory requirements. Pre-deployment reviews We launched an internal workflow tool to centralize responsible AI requirements and simplify documentation for pre-deployment reviews. Sensitive uses of AI We continued to provide hands-on counseling for high-impact and higher-risk uses of AI, particularly in areas related to healthcare and the sciences. Investments in research We established the AI Frontiers lab to push the frontier of AI capabilities, efficiency, and safety . Coherent governance frameworks We collaborated with stakeholders around the world to make progress towards building coherent governance frameworks. Responsible AI transparency Build How we build Decide How we decide Support How we support Learn How we learn View the 2025 report Follow Responsible AI transparency | Build How we build AI responsibly Learn how we build How we build generative AI systems and models responsibly When we embark on the development and deployment of a new AI system, we enlist the AI Risk Management Framework created by the National Institute for Standards and Technology (NIST), which includes four key functions: govern, map, measure, and manage. Govern: Our responsible AI governance architecture helps us uphold our principles consistently across the company. It involves establishing clear policies, processes, roles, and responsibilities. Map: Mapping and prioritizing risks enables us to make informed decisions about mitigations and the appropriateness of an AI application for a given context. Measure: AI risk measurement helps inform the prioritization and design of mitigations—a practice that grew in importance in 2024 as AI capabilities became more complex. Manage: Once we’ve mapped and measured risks, we manage them across the AI technology stack through a &#8220;defense in depth&#8221; approach. After deployment, we continue to manage risks through ongoing monitoring. Case study Managing AI-related risks in 2024 elections In 2024, more people voted in elections across the world than at any other time in history. Microsoft took proactive measures in partnership with governments, nonprofit organizations, and private sector companies to prevent the creation and dissemination of deceptive AI-generated election content. Learn more Responsible AI transparency | Decide How we make decisions Learn how we make decisions How we make decisions about releasing generative AI systems and models Throughout 2024, we continued to refine our pre-deployment oversight processes which include our deployment safety process for generative AI systems and models, as well as the Sensitive Uses and Emerging Technology program. We also launched an internal workflow tool to further support responsible AI documentation and review processes. Deployment safety for generative AI systems and models Before deploying our generative AI applications and models, teams review their risk management approach with experts across the Responsible AI Community. These experts provide recommendations and requirements grounded in our responsible AI policies. &nbsp; Learn more Sensitive Uses and Emerging Technologies program Our Sensitive Uses and Emerging Technologies program provides pre-deployment review and oversight of high-impact and higher-risk uses of AI. Reviews often culminate in requirements that go beyond our Responsible AI Standard. &nbsp; Learn more 77% generative AI In 2024, 77% of cases that received consultations from the Sensitive Uses and Emerging Technologies team were related to generative AI. Case study Safely deploying Phi small language models The Phi model team released three collections of Phi models in 2024 and early 2025, each unlocking new capabilities. The team used a &#8220;break-fix&#8221; framework to inform deployment safety for each release. Learn more Case study Safely deploying Smart Impression Smart Impression is an AI-powered productivity tool for radiologists. Through the Sensitive Uses review process, the product team identified and mitigated key risks related to using AI in a healthcare setting. Learn more Responsible AI transparency | Support How we support our customers Learn how we support our customers How we support our customers in building AI responsibly As developers and deployers of AI technology, it’s our responsibility to support our customers in their own responsible AI journeys. We regularly share our tools and practices with our customers and eagerly engage in dialogue to learn how we can better support them in innovating responsibly. AI Customer Commitments We continue to expand and build on the AI Customer Commitments we first announced in 2023. In 2024, we extended our Customer Copyright Commitments to include our reseller partners. &nbsp; Learn more Tooling to support customers Responsible AI tooling is critical to achieving consistent alignment with our internal AI policies. We’ve released 30 responsible AI tools that include more than 155 features to support our customers’ responsible AI development. &nbsp; Learn more Transparency to support customers We’re committed to equipping our customers with the information they need to innovate responsibly. Since 2019, we’ve published 40 Transparency Notes containing key information about our platform services. &nbsp; Learn more Case study Content credentials on LinkedIn Microsoft-owned platform LinkedIn became the first professional networking platform to display the C2PA Content Credentials for all AI-generated images and videos uploaded to LinkedIn’s feed. Learn more Responsible AI transparency | Learn How we learn, evolve, and grow Explore our approach How we learn, evolve, and grow in our responsible AI work From the beginning, Microsoft has committed to scaling our responsible AI program to meet the growing demand for this technology. For us, this means investing in research, working across sectors to advance effective global governance of AI, and tuning into a wide range of perspectives. Investments in research Throughout 2024, Microsoft researchers collaborated closely with our policy and engineering teams to push the frontiers of how we map, measure, and manage AI risks. &nbsp; Learn more Advancing AI adoption through good governance We are working with governments around the world to build globally coherent governance frameworks that enable organizations of all kinds to innovate with AI. &nbsp; Learn more Tuning in to multistakeholder input Harnessing the expertise of a wide range of stakeholders is essential to effective AI risk management. We actively seek out underrepresented voices for input on how our AI systems can be safer and more reliable. &nbsp; Learn more Over 300 papers The Accelerating Foundation Models Research (AFMR) community, founded by Microsoft Research, has published over 300 papers co-authored by computer scientists and researchers outside computer science, supporting over 123 institutions in 19 countries. Case study AILuminate from MLCommons Advancing AI governance requires standardizing methods for evaluating AI risks. To support this effort, MLCommons developed a new AI safety benchmark called AILuminate, which offers a scientific, independent analysis of large language model risk. Learn more Beyond our report Read last year's report Learn about responsible AI Visit the Reports Hub --> What&#39;s new Surface Pro Surface Laptop Surface Laptop Studio 2 Copilot for organizations Copilot for personal use AI in Windows Explore Microsoft products Windows 11 apps Microsoft Store Account profile Download Center Microsoft Store support Returns Order tracking Certified Refurbished Microsoft Store Promise Flexible Payments Education Microsoft in education Devices for education Microsoft Teams for Education Microsoft 365 Education How to buy for your school Educator training and development Deals for students and parents AI for education Business Microsoft AI Microsoft Security Dynamics 365 Microsoft 365 Microsoft Power Platform Microsoft Teams Microsoft 365 Copilot Small Business Developer &amp; IT Azure Microsoft Developer Microsoft Learn Support for AI marketplace apps Microsoft Tech Community Microsoft Marketplace Marketplace Rewards Visual Studio Company Careers About Microsoft Company news Privacy at Microsoft Investors Diversity and inclusion Accessibility Sustainability English (United States) Your Privacy Choices Opt-Out Icon Your Privacy Choices Your Privacy Choices Opt-Out Icon Your Privacy Choices Consumer Health Privacy Sitemap Contact Microsoft Privacy Manage cookies Terms of use Trademarks Safety &amp; eco Recycling About our ads &#169; Microsoft 2026