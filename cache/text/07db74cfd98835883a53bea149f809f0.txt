Company Overview May 2025 Certain matters in this presentation including, but not limited to, statements as to: expectations with respect to growth, performance and benefits of NVIDIA‚Äôs products, services, and technologies, including Blackwell, and related trends and drivers; expectations with respect to supply and demand for NVIDIA‚Äôs products, services, and technologies, including Blackwell, and related matters including inventory, production and distribution; our financial position; projected market growth and trends, market opportunity, demand, and growth drivers; our financial and business outlook; our dividend program; expectations with respect to NVIDIA‚Äôs third party arrangements, including with its collaborators and partners; third parties adopting our products and technologies; expectations with respect to technology developments and related trends and drivers; expectations with respect to AI and related industries; our sustainability goals; and other statements that are not historical facts are forward-looking statements within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934, as amended, which are subject to the ‚Äúsafe harbor‚Äù created by those sections based on management‚Äôs beliefs and assumptions and on information currently available to management and are subject to risks and uncertainties that could cause results to be materially different than expectations. Important factors that could cause actual results to differ materially include: global economic and political conditions; NVIDIA‚Äôs reliance on third parties to manufacture, assemble, package and test NVIDIA‚Äôs products; the impact of technological development and competition; development of new products and technologies or enhancements to NVIDIA‚Äôs existing product and technologies; market acceptance of NVIDIA‚Äôs products or NVIDIA‚Äôs partners' products; design, manufacturing or software defects; changes in consumer preferences or demands; changes in industry standards and interfaces; unexpected loss of performance of NVIDIA‚Äôs products or technologies when integrated into systems; and changes in applicable laws and regulations, as well as other factors detailed from time to time in the most recent reports NVIDIA files with the Securities and Exchange Commission, or SEC, including, but not limited to, its annual report on Form 10-K and quarterly reports on Form 10-Q. Copies of reports filed with the SEC are posted on the company‚Äôs website and are available from NVIDIA without charge. These forward-looking statements are not guarantees of future performance and speak only as of the date hereof, and, except as required by law, NVIDIA disclaims any obligation to update these forward-looking statements to reflect future events or circumstances. Many of the products and features described herein remain in various stages and will be offered on a when-and-if-available basis. The statements within are not intended to be, and should not be interpreted as a commitment, promise, or legal obligation, and the development, release, and timing of any features or functionalities described for our products is subject to change and remains at the sole discretion of NVIDIA. NVIDIA will have no liability for failure to deliver or delay in the delivery of any of the products, features or functions set forth herein. NVIDIA uses certain non-GAAP measures in this presentation including non-GAAP operating income, non-GAAP operating margin, and free cash flow. NVIDIA believes the presentation of its non-GAAP financial measures enhances investors' overall understanding of the company's historical financial performance. The presentation of the company's non-GAAP financial measures is not meant to be considered in isolation or as a substitute for the company's financial results prepared in accordance with GAAP, and the company's non-GAAP measures may be different from non-GAAP measures used by other companies. Further information relevant to the interpretation of non-GAAP financial measures, and reconciliations of these non-GAAP financial measures to the most comparable GAAP measures, may be found in the slide titled ‚ÄúReconciliation of Non-GAAP to GAAP Financial Measures.‚Äù NVIDIA‚Äôs invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined computer graphics, revolutionized accelerated computing, ignited the era of modern AI, and is fueling industrial digitalization across markets. Today, two transitions are occurring simultaneously‚Äîaccelerated computing and generative AI‚Äîtransforming the computer industry and every other industry worldwide, and NVIDIA is enabling these transitions with our full-stack computing platform and data-center-scale offerings. NVIDIA‚Äôs platform is installed in several hundred million computers, is available in every cloud and from every server maker, powers over 75% of the TOP500 supercomputers, and has ~5.9 million developers. NVIDIA Headquarters: Santa Clara, CA | Headcount: ~36,000 Grace Blackwell MGX Node NVLink Switch Quantum Switch Spectrum-X Switch Chips Purpose-Built for AI Supercomputing GPU | CPU | DPU | NIC | NVLink Switch | IB Switch | ENET Switch CUDA ‚Ä¢ DOCA ‚Ä¢ NCCL Cluster-Scale Software System Software Chip Software CUDA-X Libraries NIM CUDA-Accelerated Agentic AI Libraries Omniverse CUDA-Accelerated Physical AI Libraries Accelerated Software Stack GB200 NVL72 SuperPOD NVIDIA‚Äôs Accelerated Computing Platform Data center scale innovation across chips, networking, systems, software, and algorithms NVIDIA has accelerated software and compute by a 1,000,000X in the last decade, far surpassing Moore‚Äôs law. Accelerated computing requires full-stack innovation‚Äî optimizing across every layer of computing‚Äîfrom chips and systems to software and algorithms, demanding deep understanding of the problem domain. Our platform extends from the cloud and enterprise data centers to supercomputing, edge computing, PCs, and robotics. What Is Accelerated Computing? Not just a superfast chip‚Äîaccelerated computing is a full-stack combination of: ‚Ä¢ Chip(s) with specialized processors ‚Ä¢ Algorithms in acceleration libraries ‚Ä¢ Domain experts to refactor applications To speed up compute-intensive parts of an application A full-stack approach: silicon, systems, software For example: ‚Ä¢ If 90% of the runtime can be accelerated by 100X, the application is sped up 9X ‚Ä¢ If 99% of the runtime can be accelerated by 100X, the application is sped up 50X ‚Ä¢ If 80% of the runtime can be accelerated by 500X, or even 1,000X, the application is sped up 5X Amdahl‚Äôs law: The overall system speed-up (S) gained by optimizing a single part of a system by a factor (s) is limited by the proportion of execution time of that part (p). ùëÜ = 1 1 ‚àí ùëù + ùëù ùë† Why Accelerated Computing? Accelerated computing is needed to tackle the most impactful opportunities of our time‚Äîlike AI, climate simulation, drug discovery, ray tracing, and robotics. NVIDIA is uniquely dedicated to accelerated computing‚Äî working top-to-bottom, refactoring applications and creating new algorithms, and bottom-to-top inventing new specialized processors, like RT Cores and Tensor Cores. Advancing computing in the post-Moore‚Äôs law era 102 103 104 105 106 107 109 108 1980 1990 2000 2010 2020 2030 GPU-Computing perf 2X per year 1,000X In 10 years Single-threaded CPU perf 1.5X perf per year 1.1X per year Trillions of Operations per Second (TOPS) ‚ÄúIt‚Äôs the end of Moore‚Äôs law as we know it.‚Äù ‚ÄîJohn Hennessy, Oct 2018 ‚ÄúMoore‚Äôs law is dead.‚Äù ‚ÄîJensen Huang, GTC 2013 Computing at Inflection Point NVIDIA DC Revenue Data Center Capex (Dell‚ÄôOro Projections) $250 $1,000 $750 $500 2026 2027 202820252022 2023 2024 $1T+ NVIDIA‚Äôs Accelerated Computing Ecosystem ‚Ä¢ The NVIDIA accelerated computing platform has attracted the largest ecosystem of developers, supporting a rapidly growing universe of applications and industry innovation. ‚Ä¢ Developers can engage with NVIDIA through CUDA‚Äî our parallel computing programming model introduced in 2006‚Äîor at higher layers of the stack, including libraries, pretrained AI models, SDKs, and other development tools. *Cumulative AI Startups 2021 2024 7K 19K Developers 2021 2024 5.1M 2.5M CUDA Downloads* GPU-Accelerated Applications 2021 2024 3,700 1,700 2021 2024 53M 26M AI Driving a Powerful Investment Cycle and Significant Returns AI Agents will take action to automate tasks at superhuman speed, transforming businesses and freeing workers to focus on other tasks. Copilots based on LLMs will generate documents, answer questions, or summarize missed meetings, emails, and chats‚Äîadding hours of productivity per week. Specialized for fields such as software development, legal services or education and can boost productivity by as much as 50%. Social media, search, and e-commerce apps are using deep recommenders to offer more relevant content and ads to their customers, increasing engagement and monetization. Creators can generate stunning, photorealistic images with a single text prompt‚Äîcompressing workflows that take days or weeks into minutes in industries from advertising to game development. Call center agents augmented with AI chatbots can dramatically increase productivity and customer satisfaction. Drug discovery and financial services are seeing order-of-magnitude workflow acceleration from AI. Manufacturing workflows are reinvented and automated through generative AI and robotics, boosting productivity. AI can augment creativity and productivity by orders of magnitude across industries Source: Goldman Sachs, Cowen, Statista, Capital One, Wall Street Journal, Resource Watch, NVIDIA internal analysis AI Content Creation 50M creators globally Financial Services 678B annual credit card transactions Manufacturing $50T of heavy industry Customer Service 15M call center agents globally AI Agents & Copilots Over 1B knowledge workers Legal Services, Education 1M legal professionals in the US 9M educators in the US Search & Social Media $700B in digital advertising annually AI Software Development 30M software developers globally Drug Discovery 1018 molecules in chemical space 40 exabytes of genome data Generative AI The most important computing platform of our generation The era of generative AI has arrived, unlocking new opportunities for AI across many different applications. Generative AI is trained on large amounts of data to find patterns and relationships, learning the representation of almost anything with structure. It can then be prompted to generate text, images, video, code, or even proteins. For the very first time, computers can augment the human ability to generate information and create. 1,600+ generative AI companies are building on NVIDIA. TEXT SOUND TEXT TEXT IMAGE VIDEO SPEECH MULTI-MODAL AMINO ACID BRAINWAVES SPEECH IMAGE VIDEO IMAGE 3D ANIMATION MANIPULATION PROTEIN Learn and Understand Everything Blackwell 40X Hopper Inference Performance NVLink flops per watt ~ AI factory output 100 MW AI Factory H100 NVL8 GB200 NVL72 GPU Dies 45K 85K Racks 1,400 600 Data Center Productivity 300M 12,000M 40X More Token Revenue DeepSeek R1 Context and Generation, , ISL=32K, OSL=8K @ Pareto optimal TPS/User AI Factories‚ÄîA New Class of Data Centers AI factories are a new form of computing infrastructure. Their purpose is not to store user and company data or run ERP and CRM applications. AI factories are highly optimized systems purpose-built to process raw data, refine it into models, and produce monetizable tokens with great scale and efficiency. In the AI industrial revolution, data is the raw material, tokens are the new commodity, and NVIDIA is the token generator in the AI factory. Every company will produce digital intelligence. Tokens will be transformed into intelligent responses and actions of digital nurses, tutors, customer service agents, chip designers, manufacturing robots and autonomous cars, Weather prediction agents will warn us of storms. Some companies will build and operate AI factories, while others will rent. Countries are awakening to the need to treat their data as a national resource and AI factories as an essential national infrastructure. Data encodes a nation's history, knowledge, and culture, and can be transformed into the sovereign AI for its companies, startups, universities, and governments. NVIDIA builds the complete AI system and licenses NVIDIA AI Enterprise, the AI stack and operating system for AI factories. Production of digital intelligence tokens Data Tokens AI Factory Extending NVIDIA Networking to Scale Up & Scale Out AI in Any Data Center New NVLink and Spectrum-X increase networking opportunity beyond InfiniBand to every data center Generative AI is a Data Center-Scale Computing Workload Limitless scaling with NVLINK + InfiniBand or Spectrum-X NVIDIA NVLink Fastest Interconnect for GPU Scale-Up NVIDIA InfiniBand Supercomputing and Dedicated AI Factories NVIDIA Spectrum-X Ethernet Optimized for Multi-Tenant AI Factories# of GPU in a Data Center NVIDIA Spectrum-X AI Ethernet Fabric 10 100 1K 100K10K 1M+ AI Performance InfiniBand NVLink and InfiniBand / Spectrum-X Traditional Ethernet Accelerated Computing Starts With CUDA Libraries Unlike CPU general-purpose computing, GPU-accelerated computing requires software and algorithms to be redesigned. Software is not automatically accelerated in the presence of a GPU or accelerator. NVIDIA CUDA libraries encapsulate NVIDIA-engineered algorithms that enable applications to be accelerated on NVIDIA‚Äôs installed base. They deliver dramatically higher performance‚Äîcompared to CPU-only alternatives‚Äîacross application domains, including AI and high-performance computing, and significantly reduce runtime, cost, and energy, while increasing scale. With over 400 CUDA libraries, NVIDIA can address many major workloads across a wide range of industries. As new libraries become available, they unlock new markets adding to our long-term opportunity. Delivering up to 200X speedup across major workloads Speech AI Riva, TensorRT, Triton Inference Server, NeMo, cuBLAS, cuDNN, cuFFT, CUTLASS ~30X Recommender Systems Merlin, HugeCTR, TensorRT, Triton Inference Server, cuBLAS, cuDNN, cuFFT, cuSPARSE, CUTLASS, Magnum IO, NCCL, cuVS ~50X Deep Learning cuDNN, CUTLASS, Megatron, TensorRT, TRT LLM, NCCL, NV-Triton, CUDA-optimized PyTorch, Tensorflow, Triton, Jax ~100X Science Earth-2 CorrDiff, Holoscan, Parabricks, Monai, Modulus, Warp, cuLitho, cuQuantum, CUDA-Q, AmgX, cuDSS, cuFFT, cuSOLVER, cuBLAS, cuSPARSE, cuTENSOR, cuGraph, Magnum IO, NCCL, NVSHMEM, RAFT, cuNumeric, Sionna ~100X Agentic and Physical AI ACE, Riva, Nemo, Tokkio Digital Human, Holoscan, Metropolis, Omniverse, Isaac, DRIVE, cuLitho, cuMotion, cuOpt, Aerial CUDA-accelerated RAN, Sionna, fVDB, PhysX, Warp, NVblox ~100X Computer Vision CV-CUDA, Deepstream, TAO, Holoscan, cuCIM, TensorRT, Triton Inference Server, DALI, nvImageCodec, cuDNN, nvJPEG, nvJPEG2000, nvTIFF, NPP, Video Codec SDK, Magnum IO, NCCL, cuVS, DALI ~200X Data Processing cuVS, cuDF-Spark, cuDF-pandas, cuDF-Polars, cuGraph, cuML, XGBoost, RAPIDS, NeMo Curator, cuSOLVER, cuIO ~200X Accelerated Computing Is Sustainable Computing Order of magnitude more energy efficient Energy Usage in AI Inference GPT-MoE-1.8T energy per token Accelerated computing requires higher peak power consumption than CPUs, however, completes workloads significantly faster and consumes less total energy Time(sec) Server TDP (kW) Kepler 42000 Joules/Token Pascal 17640 J/Token Volta 1200 J/Token Ampere 150 J/Token Hopper 10 J/Token Blackwell 0.4 J/Token 2014 2024 Accelerated computing enables full-stack optimization from algorithm to GPU architecture, such as Tensor Core Transformer Engine; LLM energy efficiency improved 100,000X in the past 10 years CPU NVIDIA AI Scaling Laws Drive Exponential Demand for Compute Reasoning AI Inference Compute >100X One-Shot ‚ÄúIntelligence‚Äù Perception AI Generative AI Agentic AI Physical AI From One to Three Scaling Laws Pre-Training Scaling Post-Training Scaling Test-Time Scaling ‚ÄúLong Thinking‚Äù Step 1 Step 2 Step 3 Prompt Step 1 Step 2 LLM LLM LLM NVIDIA Is the Leading Inference Platform Inference compute scales exponentially with ‚Äúlong thinking‚Äù Flash Attention KVCache PageAttention Distillation Pruning & Quantization Neural Architecture Search Disaggregated Serving Speculative Decoding Multi-GPU, Multi-Node Hopper inference performance increased 5X in 1 year with rapid algorithm innovations enabled by rich NVIDIA CUDA ecosystem Installed base & CUDA ‚ûî rapid software innovation ‚ûî performance ‚ûî lower inference cost ‚ûî increase demand ‚ûî increase installed base Inference compute scaling exponentially with large multimodal models, chain-of-thought, reasoning, agents, and low-latency responses GB200 NVL72 NVLink Switches 130 TB/s All-to-All BW One Giant Blackwell 1.44 EF FP4 576TB/s HBM3e 0 100,000 200,000 300,000 400,000 500,000 600,000 700,000 800,000 900,000 1,000,000 0 100 200 300 400 500 600 TPS / MW EP64PP2+PP4, Batch 224, 50% Context EP64PP4+PP4, Batch 224, 46% Context EP64PP4+PP4, Batch 160, 44% Context EP64+EP4, Batch 16, 43% Context, MTP On EP64+EP4, Batch 8, 36% Context, MTP On EP64+EP4, Batch 4, 29% Context, MTP On EP64+EP4, Batch 2, 19% Context, MTP On EP64+EP4, Batch 1, 12% Context, MTP On TEP4+EP4, Batch 1, 3% Context, MTP On TEP8+EP4, Batch 1, 2%Context, MTP On TEP16+EP4, Batch 1, 1% Context, MTP On TEP32+EP4, Batch 1, 1% Context, MTP On EP64PP2+PP4, Batch 480, 52% Context EP64PP2+PP4, Batch 160, 48% Context TPS for 1 User EP64+EP4, Batch 32, 47% Context, MTP On Throughput Hopper FP8 NVL8 Dynamo Blackwell FP4 NVL72 Dynamo Smart AI Fast Response Blackwell 40X Hopper FP4 | NVL72 | Dynamo | TRT-LLM continuous optimization | 32K ISL/8K OSL NVIDIA NVLink Enables New Level of AI Training & Inference Scaling NVLink Switch GB200 NVL72 NVLink Switches 130 TB/s All-to-All BW One Giant Blackwell 1.44 EF FP4 576TB/s HBM3e Ecosystem NVIDIA AI Platform and Ecosystem Reaches Every Market Every workload to address the world‚Äôs industries Accelerate Every Workload Full-Stack, Entire AI Infrastructure Software Data Pre- Processing Training Post Training e.g., SDG Agentic AI Inference Robotic AI Inference AI Infrastructure AI Technology Every Cloud OEMs and ODMs PC and Workstations Edge and Robotics Full-Stack Compute-to-Networking Sovereign AI Regional CSPs Telcos Internet Services Public Clouds Heavy Industries Enterprises Auto, Healthcare, Logistics, Energy, FSI, etc. AI Startups SaaS Social Media Platforms NVIDIA AI Enterprise Enables IT Ecosystem With State-of-the-Art AI Models and Libraries to Build Agentic AI . . . Cloud and On-Prem Infrastructure System Integrators . . . Enterprise ISVs NVIDIA AI Enterprise Ecosystem NVIDIA NeMo User NVIDIA NeMo Retriever Vector Database Action Structured Database NVIDIA NIM Data Flywheel AI Agent . . . Data Platforms . . . Reinventing $500B Enterprise IT for the Age of AI Compute Networking Storage AI OS Infrastructure Prefill Decode Query KV $ NVIDIA Omniverse and AI Revolutionizing Manufacturing and Robotics 10M Factories 200K Warehouses 100M Cars Billions in Future The next AI wave is physical AI‚Äîmodels that can perceive, understand, and interact with the physical world. Physical AI will embody robotic systems‚Äîfrom autonomous vehicles to industrial robots and humanoids, to warehouses and factories. Three computers and software stacks are required to build physical AI: NVIDIA AI on DGX to train the AI model, NVIDIA Omniverse on OVX to teach, test, and validate the AI model‚Äôs skills, and NVIDIA AGX to run the AI software on the robot. Enterprises license NVIDIA Omniverse at $4,500 per GPU per year. Sovereign AI Nations produce AI using their own data, infrastructure, workforce, and business networks Japan National Institute of Advanced Industrial Science and Technology (AIST) Switzerland Swisscom Group Ecuador Telconet Singapore Singapore Telecommunications Limited (Singtel) France Scaleway Vietnam FPT Smart Cloud Spain Barcelona Supercomputing Center Location of NVIDIA sovereign AI partners Sovereign AI Nations are awakening to the imperative to produce AI using their own infrastructure, data, workforces, and business networks. Nations are building domestic computing capacity. Some governments operate sovereign AI clouds in collaboration with state- owned telecommunications providers or utilities. Other governments partner with local cloud providers to deliver a shared AI computing infrastructure for public and private-sector use. NVIDIA‚Äôs ability to help build AI infrastructure with our end-to-end compute-to-networking technologies, full-stack software, AI expertise, and rich ecosystem of partners and customers allows sovereign AI and regional cloud providers to jump-start their countries‚Äô AI ambitions. $16,675 $26,914 $26,974 $60,922 $130,497 $44,062 FY21 FY22 FY23 FY24 FY25 Q1 FY26 $6,803 $12,690 $9,040 $37,134 $86,789 $23,27541% 47% 34% 61% 67% 53% 30% 40% 50% 60% 70% $0 $10,000 $20,000 $30,000 $40,000 $50,000 $60,000 $70,000 $80,000 $90,000 FY21 FY22 FY23 FY24 FY25 Q1 FY26 Operating Income (Non-GAAP, $M) Operating Margin (Non-GAAP) Driving Strong and Profitable Growth Fiscal year ends in January. Refer to Appendix for reconciliation of Non-GAAP measures. Operating margins rounded to the nearest percent. Q1 FY26 included a $4.5 billion charge associated with H20 excess inventory and purchase obligations. Revenue ($M) $4.7B $8.0B $3.8B $26.9B $60.7B $26.1B FY21 FY22 FY23 FY24 FY25 Q1 FY26 Strong Cash Flow Generation Fiscal year ends in January. Refer to Appendix for reconciliation of Non-GAAP measures. Free Cash Flow (Non-GAAP) Capital Allocation 1 Subject to continuing determination by our Board of Directors. Share Repurchase Utilized $14.1B of cash for repurchases in Q1 FY26 $24.3B remaining authorization as of the end of Q1 Dividend $244M in Q1 FY26 Plan to Maintain1 Strategic Investments Growing Our Talent Platform Reach and Ecosystem DRIVE Hyperion sensor architecture with AGX compute DRIVE AV & IX full-stack software for ADAS, AV, and AI cockpit DGX/HGX/MGX/IGX systems GPU | CPU | DPU | Networking NVIDIA AI software Our Market Platforms at a Glance FY25 Revenue $115.2B 5-YR CAGR 108% FY25 Revenue $11.4B 5-YR CAGR 16% FY25 Revenue $1.9B 5-YR CAGR 9% FY25 Revenue $1.7B 5-YR CAGR 19% GeForce GPUs for PC gaming GeForce NOW cloud gaming NVIDIA RTX GPUs for workstations Omniverse software Professional Visualization Automotive 9% of FY25 Revenue 1% of FY25 Revenue 1% of FY25 Revenue Data Center 88% of FY25 Revenue Gaming Data Center The leading accelerated computing platform Leader in AI and HPC No. 1 in AI training and inference Used by all hyperscalers, major cloud computing providers, and over 40,000 companies Powers over 75% of the TOP500 supercomputers Growth Drivers Broad data center platform transition from general-purpose to accelerated computing Emergence of AI factories‚Äîoptimized for refining data and training, inferencing, and generating AI Broader and faster product launch cadence to meet a growing and diverse set of AI opportunities NVIDIA AI Enterprise/NIM for building and running enterprise AI applications 108% 5-YR CAGR Through FY25 Revenue ($M) $6,696 $10,613 $15,005 $47,525 $115,186 $39,112 FY21 FY22 FY23 FY24 FY25 Q1 FY26 2025 2026 2027 2028 COMPUTE Blackwell 8S HBM3e Blackwell Ultra 8S HBM3e Spectrum7 204T, CPO CX10 Feynman Next‚ÄìGen HBM Vera CPU Rubin 8S HBM4 Rubin Ultra 16S HBM4e Oberon NVL72 Liquid Cooled Kyber NVL576 Liquid Cooled Blackwell Feynman NVLINK (SCALE-UP) NETWORKING (SCALE-OUT) Grace CPU 5th Gen NVL 72 1800 GB/s Spectrum5 51T CX8 800G Spectrum6 102T, CPO CX9 1600G 6th Gen NVSwitch 3600 GB/s Vera CPU 7th Gen NVSwitch 3600 GB/s SYSTEM 8th Gen NVSwitch NVL-Next Rubin NVIDIA Paves Road to Gigawatt AI Factories One-Year rhythm | Full-stack | One architecture | CUDA everywhere Gaming GeForce‚Äîworld‚Äôs largest gaming platform Leader in PC Gaming Strong No. 1 market position 15 of the top 15 most popular GPUs on Steam Leading performance and innovation 200M+ gamers on GeForce Growth Drivers Rising adoption of NVIDIA RTX in games Expanding universe of gamers and creators Gaming laptops and generative AI on PCs GeForce NOW cloud gaming 16% 5-YR CAGR Through FY25 Revenue ($M) $7,759 $12,462 $9,067 $10,447 $11,350 $3,763 FY21 FY22 FY23 FY24 FY25 Q1 FY26 Professional Visualization Workstation graphics Leader in Workstation Graphics 95%+ market share in graphics for workstations 45M designers and creators Strong software ecosystem with over 100 RTX accelerated and supported applications Growth Drivers Generative AI adoption across design and creative industries Enterprise AI development, model fine-tuning, cross-industry Ray tracing revolutionizing design and content creation Expanding universe of designers and creators Omniverse for digital twins and collaborative 3D design Hybrid work environments Revenue ($M) 9% 5-YR CAGR Through FY25 $1,053 $2,111 $1,544 $1,553 $1,878 $509 FY21 FY22 FY23 FY24 FY25 Q1 FY26 Automotive Autonomous vehicles and AI cockpits Leader in Autonomous Driving NVIDIA DRIVE an end-to-end autonomous vehicle (AV) and AI cockpit platform featuring a full software stack and powered by NVIDIA SoCs (systems-on-a-chip) in vehicles DRIVE Orin SoC ramp began in FY23 Next-generation DRIVE Thor SoC ramp to begin in FY26 Over 40 customers including 20 of top 30 EV makers, 7 of top 10 truck makers, 8 of top 10 robotaxi makers Growth Drivers Adoption of centralized car computing and software-defined vehicle architectures AV software and services: Mercedes-Benz Jaguar Land Rover Revenue ($M) 19% 5-YR CAGR Through FY25 $536 $566 $903 $1,091 $1,694 $567 FY21 FY22 FY23 FY24 FY25 Q1 FY26 The $1T installed base of general-purpose CPU data center infrastructure is being modernized to a new GPU-accelerated computing paradigm. The entire computing stack has been reinvented‚Äî from CPU to GPU, from coding to machine learning, from software to generative AI. Computers generate intelligence tokens, a new commodity. A new type of data center, AI factories, isexpanding the data center footprint to $2T and beyond in the coming years. Eventually,companies in every industry will operate AI factories as the digital twin of their workforce, manufacturing plants, and products. A new industrial revolution has begun. Accelerated Computing and Generative AI Create Trillion-Dollar Opportunities GPU-Accelerated Data Centers AI Factories Traditional Data Centers General-Purpose Computing AI Accelerated Computing Financials Cash Balance‚Äî$M 11,561 21,208 13,296 25,984 43,210 FY21 FY22 FY23 FY24 FY25 Operating Cash Flow‚Äî$M 5,822 9,108 5,641 28,090 64,089 FY21 FY22 FY23 FY24 FY25 Free Cash Flow (Non-GAAP)‚Äî$M 4,677 8,049 3,750 26,947 60,724 FY21 FY22 FY23 FY24 FY25 Operating Income (Non-GAAP)‚Äî$M 6,803 12,690 9,040 37,134 86,789 FY21 FY22 FY23 FY24 FY25 Annual Cash and Cash Flow Metrics Cash balance is defined as cash and cash equivalents plus marketable securities | Refer to Appendix for reconciliation of non-GAAP measures Corporate Sustainability Fast Company Magazine‚Äôs World‚Äôs Most Innovative Companies Fortune‚Äôs World‚Äôs Most Admired Companies Time Magazine‚Äôs 100 Most Influential Companies Wall Street Journal‚Äôs Management Top 250 ‚Äú100 Most Sustainable U.S. Companies‚Äù BARRON‚ÄôS ‚ÄúAmerica‚Äôs 100 Best Companies to Work For‚Äù FORTUNE ‚ÄúAmerica‚Äôs Most Responsible Companies‚Äù NEWSWEEK NVIDIA Blackwell platform delivers a 25X improvement in energy efficiency for LLM inference compared to the Hopper generation We achieved our goal and will maintain 100% renewable electricity for offices and data centers under our operational control A Place for People to Do Their Life‚Äôs WorkEnvironmentally Conscious On track to engage manufacturing suppliers comprising at least 67% of scope 3 category 1 GHG emissions with the goal of effecting supplier adoption of science-based targets by end of FY26 Management 92% of directors are independent Corporate Governance ‚ÄúBest Places to Work‚Äù GLASSDOOR Reconciliation of Non-GAAP to GAAP Financial Measures Operating Income and Margin ($ in Millions and Margin Percentage) Non-GAAP Acquisition Termination Cost Acquisition-Related and Other Costs (A) Stock-Based Compensation (B) Other (C) GAAP FY 2021 $6,803 ‚Äî (836) (1,397) (38) $4,532 40.8% ‚Äî (5.0) (8.4) (0.2) 27.2% FY 2022 $12,690 ‚Äî (636) (2,004) (9) $10,041 47.2% ‚Äî (2.5) (7.4) ‚Äî 37.3% FY 2023 $9,040 (1,353) (674) (2,710) (79) $4,224 33.5% (5.0) (2.5) (10.0) (0.3) 15.7% FY 2024 $37,134 ‚Äî (583) (3,549) (30) $32,972 61.0% ‚Äî (1.0) (5.8) (0.1) 54.1% FY 2025 $86,789 ‚Äî (602) (4,737) 3 $81,453 66.5% ‚Äî (0.5) (3.6) ‚Äî 62.4% Q1‚Äô25 $18,059 ‚Äî (140) (1,011) 1 $16,909 69.3% ‚Äî (0.5) (3.9) ‚Äî 64.9% Q1‚Äô26 $23,275 ‚Äî (160) (1,474) (3) $21,638 52.8% ‚Äî (0.4) (3.3) ‚Äî 49.1% Reconciliation of Non-GAAP to GAAP Financial Measures A. Consists of amortization of acquisition-related intangible assets, inventory step-up, transaction costs, compensation charges, and other costs B. Stock-based compensation charge was allocated to cost of goods sold, research and development expense, and sales, general and administrative expense C. Comprises of legal settlement cost, contributions, restructuring costs and assets held for sale related adjustments ($ in Millions) Free Cash Flow Purchases Related to Property and Equipment and Intangible Assets Principal Payments on Property and Equipment and Intangible Assets Net Cash Provided by Operating Activities FY 2021 $4,677 1,128 17 $5,822 FY 2022 $8,049 976 83 $9,108 FY 2023 $3,750 1,833 58 $5,641 FY 2024 $26,947 1,069 74 $28,090 FY 2025 $60,724 3,236 129 $64,089 YTD Q1‚Äô25 $14,936 369 40 $15,345 YTD Q1‚Äô26 $26,135 1,227 52 $27,414 Reconciliation of Non-GAAP to GAAP Financial Measures (contd.)