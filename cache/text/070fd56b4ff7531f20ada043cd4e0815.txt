10 0 10 1 10 2 10 3 10 4 10 5 10 7 10 6 1970 1980 1990 2000 2010 2020 Dennard Scaling Stops Power Frequency Single-Thread Performance (SpecINT) # of Transistors Microprocessor Trend Data CPU GPU CPU General Purpose to GPU Accelerated Computing Platform Shift Accelerated Computing Begins with CUDA-X Libraries AI 6G Quantum Enterprise Robotics FactoriesModels Announcing NVIDIA and Nokia Pioneer the AI Era of Telecommunications Announcing Nokia to Build AI-Native 6G on New NVIDIA ARC “Aerial RAN Computer” Aerial RAN Computer Nokia MIMO Radio NVQLink Launches Quantum-GPU Computing NVQLink Oak Ridge National Laboratory and the oak leaf symbol are registered trademarks of the U.S. Department of Energy. Use of this mark does not constitute or imply its endorsement, recommendation, or favoring by the United States Government or any agency thereof or its contractors or subcontractors. Announcing NVIDIA NVQLink ― Quantum-GPU Interconnect CUDA-Q | cuQuantum | CUDA CPUGPU NVLink QPU NVQLink Announcing Department of Energy Partners with NVIDIA to Build 7 New AI Supercomputers Argonne National Laboratory Solstice – 100K Blackwell GPUs Equinox Tara Minerva Janus Los Alamos National Laboratory Powered by Vera Rubin Mission Vision Grace Blackwell NVL72 “A Thinking Machine” NVLink All-to-All Switch Point-to-Point 8 GPUs x 9 Servers All-to-All NVLink Switch 72 GPUs x 1 Rack 1,800 GB/s GPU-to-GPU Bandwidth 4 Experts 4 Experts 4 Experts 4 Experts 32 Experts 32 Experts 32 Experts 32 Experts 32 Experts 32 Experts 32 Experts 32 Experts 4 Experts 4 Experts 4 Experts 4 Experts Ethernet Extreme Co-Designed Blackwell NVL72 Game-Changer for Mixture-of-Experts Models Token Throughput per Megawatt (TPS/GPU) InferenceMAX by Token Throughput per MW vs. Interactivity DeepSeek R1 0528 · FP4 · 8K/1K · Source: SemiAnalysis InferenceMAXTM 0 1,500,000 3,000,000 4,500,000 6,000,000 0 35 70 105 140 175 210 245 280 315 GB200 NVL72 H200 NVL8 Interactivity (TPS/User) 10X Performance Extreme Co-Designed Blackwell NVL72 Game-Changer for Mixture-of-Experts Models 10X Perf-per-Dollar 10X Perf-per-Watt 10X Throughput 10X Revenues Cost per Million Tokens ($/M Tokens) InferenceMAX by Cost per Million Tokens vs. Interactivity DeepSeek R1 0528 · FP4 · 8K/1K · Source: SemiAnalysis InferenceMAXTM Interactivity (TPS/User) Extreme Co-Designed Blackwell NVL72 Game-Changer for Mixture-of-Experts Models 10X Perf-per-Dollar 10X Perf-per-Watt 10X Throughput 10X Revenues $0.00 $0.70 $1.40 $2.10 $2.80 0 35 70 105 140 175 210 GB200 NVL72 H200 NVL8 10X Lower Cost $126 $133 $270 $443 $549 $632 2022 2023 2024 2025 2026 2027 Source: Morgan Stanley Research Amazon, CoreWeave, Google, Meta, Microsoft, Oracle 2022 2023 2024 2025 2026 2027 $0.5T+ 20M GPUs Shipped 6M GPUs $100B 4M GPUs Blackwell and Rubin are 2 GPUs per chip. Excluding China. Driven by Two Exponentials Visibility into more than half a trillion dollars in cumulative Blackwell and Rubin revenue through CY2026 (so far) More than 5X Hopper’s lifetime revenue Exceptionally Strong Demand for Grace Blackwell NVL72 2025-26 Blackwell-Rubin (So Far) 2023-25 Hopper Lifetime NVIDIA Extreme Co-Design Delivers X-Factors on One-Year Rhythm Full-Stack | One Architecture | CUDA Everywhere Blackwell FeynmanRubinVolta Rubin 8S HBM4 Rubin Ultra 16S HBM4e Oberon NVL72 Kyber NVL576 Rubin CPX Blackwell 8S HBM3e Blackwell Ultra 8S HBM3e Grace CPU NVLink 5 Switch 1800 GB/s Spectrum5 51T NVLink 6 Switch 3600 GB/s NVLink 7 Switch 3600 GB/s CX8 800G Spectrum6 102T, CPO CX9 1600G Vera CPU Spectrum7 204T, CPO CX10 Feynman Next–Gen HBM NVLink 8 Switch Vera CPU BlueField-3 BlueField-4 BlueField-5 V100 HBM2 DGX-1 Kyber NVL576 2025 2026 2027 20282023 20242016 Vera Rubin Superchip Processor for Gigascale AI Factories 100 PF AI with 88 Custom Arm Cores 2 TB Fast Memory 6 Trillion Transistors Vera Rubin Compute Tray 200 PF NVL72 Building Block 14.4 TB/s NVLink | 800 GB/s ConnectX-9 100% Liquid-Cooled 12 Trillion Transistors Vera Rubin CPX Compute Tray 1M+ Token Context Accelerator 440 PF Inference Performance 8 Additional Rubin CPX GPUs Converged and CPX-Only Configurations Announcing NVIDIA BlueField-4 800G SmartNIC for AI Factories 64 Core Grace CPU with ConnectX-9 AI Data Storage Acceleration 126 Billion Transistors NVLink Switch Tray Scale-Up Fabric with 3.6 TB/s Per-GPU All-to-All BW NVLink6 400G Custom SerDes 28.8 TB/s Total Bandwidth 432 Billion Transistors Spectrum-X Ethernet 102.4 TB/s Scale-Out Switch Infrastructure Integrated 200G Silicon Photonics 95% Effective Bandwidth at Scale 352 Billion Transistors Announcing NVIDIA Omniverse DSX Blueprint for Gigascale AI Factories Omniverse | DSX | CUDA-X RTX PRO Server 0M 20M 40M 60M 80M 100M 120M 140M 160M Qwen Llama Mistral Gemma DeepSeek Phi gpt-oss October 2023 April 2024 October 2024 April 2025 October 2025 Developer Adoption of Open Models Total Monthly Downloads NVIDIA and Top OSS Models 23 Models on Leaderboards AIME 2025 ViDoRe, MTEB, MMTEB LLM Safety Leaderboard OpenASR PAIBench MVPBench, IntPHys, CasualVQA VLM3DLiveCodeBench Cosmos Physical AI GR00T Robotics Nemotron Agentic AI Clara Biomedical AI NVIDIA Open Models, Data, Libraries Top Leaderboards AI Startups Build on NVIDIA NVIDIA and Global Leaders Build Digital Twin Platform for US Reindustrialization NVIDIA and Global Leaders Build Digital Twin Platform for US Reindustrialization RTX PRO Server Announcing Foxconn Builds New Blackwell Factory in Texas Omniverse | Isaac Sim | Cosmos | Metropolis RTX PRO Server Caterpillar Builds Factory Digital Twin on NVIDIA Omniverse | Mega Jetson Thor GB200 RTX PRO Server Figure Builds Humanoid Robots on NVIDIA Omniverse | Isaac Lab | Cosmos Jetson Thor GB200 RTX PRO Server Agility Robotics Builds Humanoid Robots on NVIDIA Omniverse | Isaac Sim | Isaac Lab RTX PRO Server IGX Thor Johnson & Johnson Builds Medical Robots on NVIDIA Omniverse | Isaac for Healthcare | Cosmos GB200 RTX PRO Server Jetson AGX NVIDIA and Disney Research Advance Robot Learning Omniverse | Isaac Sim | Newton DRIVE AGX ECU Announcing Global Automakers Adopt NVIDIA DRIVE Hyperion Announcing Global Robotaxi Ecosystem Built on NVIDIA DRIVE Hyperion