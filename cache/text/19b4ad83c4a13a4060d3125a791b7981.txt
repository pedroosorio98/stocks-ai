Company Overview February 2025 Except for the historical information contained herein, certain matters in this presentation including, but not limited to, statements as to: expectations with respect to growth, performance and benefits of NVIDIA‚Äôs products, services, and technologies, including Blackwell, and related trends and drivers; expectations with respect to supply and demand for NVIDIA‚Äôs products, services, and technologies, including Blackwell, and related matters including inventory, production and distribution; our financial position; projected market growth and trends, market opportunity, demand, and growth drivers; our financial and business outlook; our dividend program; expectations with respect to NVIDIA‚Äôs third party arrangements, including with its collaborators and partners; third parties adopting our products and technologies; expectations with respect to technology developments and related trends and drivers; expectations with respect to AI and related industries; our sustainability goals; and other statements that are not historical facts are forward-looking statements. These forward-looking statements and any other forward-looking statements that go beyond historical facts that are made in this presentation are subject to risks and uncertainties that may cause actual results to differ materially. Important factors that could cause actual results to differ materially include: global economic and political conditions; NVIDIA‚Äôs reliance on third parties to manufacture, assemble, package and test NVIDIA‚Äôs products; the impact of technological development and competition; development of new products and technologies or enhancements to NVIDIA‚Äôs existing product and technologies; market acceptance of NVIDIA‚Äôs products or NVIDIA‚Äôs partners' products; design, manufacturing or software defects; changes in consumer preferences and demands; changes in industry standards and interfaces; unexpected loss of performance of NVIDIA‚Äôs products or technologies when integrated into systems and other factors; and changes in applicable laws and regulations. NVIDIA has based these forward-looking statements largely on its current expectations and projections about future events and trends that it believes may affect its financial condition, results of operations, business strategy, short-term and long-term business operations and objectives, and financial needs. These forward-looking statements are subject to a number of risks and uncertainties, and you should not rely upon the forward-looking statements as predictions of future events. The future events and trends discussed in this presentation may not occur and actual results could differ materially and adversely from those anticipated or implied in the forward-looking statements. Although NVIDIA believes that the expectations reflected in the forward-looking statements are reasonable, the company cannot guarantee that future results, levels of activity, performance, achievements or events and circumstances reflected in the forward-looking statements will occur. Except as required by law, NVIDIA disclaims any obligation to update these forward-looking statements to reflect future events or circumstances. For a complete discussion of factors that could materially affect NVIDIA‚Äôs financial results and operations, please refer to the reports we file from time to time with the SEC, including NVIDIA‚Äôs most recent Annual Report on Form 10-K, Quarterly Reports on Form 10-Q, and Current Reports on Form 8-K. Copies of reports we file with the SEC are posted on NVIDIA‚Äôs website and are available from NVIDIA without charge Many of the products and features described herein remain in various stages and will be offered on a when-and-if-available basis. The statements within are not intended to be, and should not be interpreted as a commitment, promise, or legal obligation, and the development, release, and timing of any features or functionalities described for our products is subject to change and remains at the sole discretion of NVIDIA. NVIDIA will have no liability for failure to deliver or delay in the delivery of any of the products, features or functions set forth herein. NVIDIA uses certain non-GAAP measures in this presentation including non-GAAP operating income, non-GAAP operating margin, and free cash flow. NVIDIA believes the presentation of its non-GAAP financial measures enhances investors' overall understanding of the company's historical financial performance. The presentation of the company's non-GAAP financial measures is not meant to be considered in isolation or as a substitute for the company's financial results prepared in accordance with GAAP, and the company's non-GAAP measures may be different from non-GAAP measures used by other companies. Further information relevant to the interpretation of non-GAAP financial measures, and reconciliations of these non-GAAP financial measures to the most comparable GAAP measures, may be found in the slide titled ‚ÄúReconciliation of Non-GAAP to GAAP Financial Measures.‚Äù NVIDIA‚Äôs invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined computer graphics, revolutionized accelerated computing, ignited the era of modern AI, and is fueling industrial digitalization across markets. Today, two transitions are occurring simultaneously‚Äîaccelerated computing and generative AI‚Äîtransforming the computer industry and every other industry worldwide, and NVIDIA is enabling these transitions with our full-stack computing platform and data-center-scale offerings. NVIDIA‚Äôs platform is installed in several hundred million computers, is available in every cloud and from every server maker, powers over 75% of the TOP500 supercomputers, and has ~5.9 million developers. NVIDIA Headquarters: Santa Clara, CA | Headcount: ~36,000 Grace Blackwell MGX Node NVLink Switch Quantum Switch Spectrum-X Switch Chips Purpose-Built for AI Supercomputing GPU | CPU | DPU | NIC | NVLink Switch | IB Switch | ENET Switch CUDA ‚Ä¢ DOCA ‚Ä¢ NCCL Cluster-Scale Software System Software Chip Software CUDA-X Libraries NIM CUDA-Accelerated Agentic AI Libraries Omniverse CUDA-Accelerated Physical AI Libraries Accelerated Software Stack GB200 NVL72 SuperPOD NVIDIA‚Äôs Accelerated Computing Platform Data center scale innovation across chips, networking, systems, software, and algorithms NVIDIA has accelerated software and compute by a 1,000,000X in the last decade, far surpassing Moore‚Äôs law. Accelerated computing requires full-stack innovation‚Äî optimizing across every layer of computing‚Äîfrom chips and systems to software and algorithms, demanding deep understanding of the problem domain. Our platform extends from the cloud and enterprise data centers to supercomputing, edge computing, PCs, and robotics. What Is Accelerated Computing? Not just a superfast chip‚Äîaccelerated computing is a full-stack combination of: ‚Ä¢ Chip(s) with specialized processors ‚Ä¢ Algorithms in acceleration libraries ‚Ä¢ Domain experts to refactor applications To speed up compute-intensive parts of an application A full-stack approach: silicon, systems, software For example: ‚Ä¢ If 90% of the runtime can be accelerated by 100X, the application is sped up 9X ‚Ä¢ If 99% of the runtime can be accelerated by 100X, the application is sped up 50X ‚Ä¢ If 80% of the runtime can be accelerated by 500X, or even 1,000X, the application is sped up 5X Amdahl‚Äôs law: The overall system speed-up (S) gained by optimizing a single part of a system by a factor (s) is limited by the proportion of execution time of that part (p). ùëÜ = 1 1 ‚àí ùëù + ùëù ùë† Why Accelerated Computing? Accelerated computing is needed to tackle the most impactful opportunities of our time‚Äîlike AI, climate simulation, drug discovery, ray tracing, and robotics. NVIDIA is uniquely dedicated to accelerated computing ‚Äîworking top-to-bottom, refactoring applications and creating new algorithms, and bottom-to-top inventing new specialized processors, like RT Cores and Tensor Cores. Advancing computing in the post-Moore‚Äôs law era 102 103 104 105 106 107 109 108 1980 1990 2000 2010 2020 2030 GPU-Computing perf 2X per year 1,000X In 10 years Single-threaded CPU perf 1.5X perf per year 1.1X per year Trillions of Operations per Second (TOPS) ‚ÄúIt‚Äôs the end of Moore‚Äôs law as we know it.‚Äù ‚ÄîJohn Hennessy, Oct 2018 ‚ÄúMoore‚Äôs law is dead.‚Äù ‚ÄîJensen Huang, GTC 2013 ‚Ä¢ The NVIDIA accelerated computing platform has attracted the largest ecosystem of developers, supporting a rapidly growing universe of applications and industry innovation. ‚Ä¢ Developers can engage with NVIDIA through CUDA‚Äîour parallel computing programming model introduced in 2006‚Äî or at higher layers of the stack, including libraries, pretrained AI models, SDKs, and other development tools. NVIDIA‚Äôs Accelerated Computing Ecosystem Developers CUDA Downloads* AI Startups GPU-Accelerated Applications 2021 2024 7K 19K 2021 2024 5.1M 2.5M 2021 2024 53M 26M 2021 2024 3,700 1700 *Cumulative AI Driving a Powerful Investment Cycle and Significant Returns AI Agents will take action to automate tasks at superhuman speed, transforming businesses and freeing workers to focus on other tasks. Copilots based on LLMs will generate documents, answer questions, or summarize missed meetings, emails, and chats‚Äîadding hours of productivity per week. Specialized for fields such as software development, legal services or education and can boost productivity by as much as 50%. Social media, search, and e-commerce apps are using deep recommenders to offer more relevant content and ads to their customers, increasing engagement and monetization. Creators can generate stunning, photorealistic images with a single text prompt‚Äîcompressing workflows that take days or weeks into minutes in industries from advertising to game development. Call center agents augmented with AI chatbots can dramatically increase productivity and customer satisfaction. Drug discovery and financial services are seeing order-of-magnitude workflow acceleration from AI. Manufacturing workflows are reinvented and automated through generative AI and robotics, boosting productivity. AI can augment creativity and productivity by orders of magnitude across industries Source: Goldman Sachs, Cowen, Statista, Capital One, Wall Street Journal, Resource Watch, NVIDIA internal analysis AI Content Creation 50M creators globally Financial Services 678B annual credit card transactions Manufacturing $50T of heavy industry Customer Service 15M call center agents globally AI Agents & Copilots Over 1B knowledge workers Legal Services, Education 1M legal professionals in the US 9M educators in the US Search & Social Media $700B in digital advertising annually AI Software Development 30M software developers globally Drug Discovery 1018 molecules in chemical space 40 exabytes of genome data Generative AI The most important computing platform of our generation The era of generative AI has arrived, unlocking new opportunities for AI across many different applications. Generative AI is trained on large amounts of data to find patterns and relationships, learning the representation of almost anything with structure. It can then be prompted to generate text, images, video, code, or even proteins. For the very first time, computers can augment the human ability to generate information and create. 1,600+ generative AI companies are building on NVIDIA. TEXT SOUND TEXT TEXT IMAGE VIDEO SPEECH MULTI-MODAL AMINO ACID BRAINWAVES SPEECH IMAGE VIDEO IMAGE 3D ANIMATION MANIPULATION PROTEIN Learn and Understand Everything Delivering Tremendous Value to Customers Significant reduction in TCO with each generation Hopper | 8,000 GPUs | 15MW Blackwell GB200 NVL72 | 2,000 GPUs | 4MW‚Äã LLM Training Workload: GPT-MoE-1.8T | Train in 90 days | H100 vs GB200 NVL72 4X Reduction in Power AI Factories‚ÄîA New Class of Data Centers AI factories are a new form of computing infrastructure. Their purpose is not to store user and company data or run ERP and CRM applications. AI factories are highly optimized systems purpose-built to process raw data, refine it into models, and produce monetizable tokens with great scale and efficiency. In the AI industrial revolution, data is the raw material, tokens are the new commodity, and NVIDIA is the token generator in the AI factory. Every company will produce digital intelligence. Tokens will be transformed into intelligent responses and actions of digital nurses, tutors, customer service agents, chip designers, manufacturing robots and autonomous cars, Weather prediction agents will warn us of storms. Some companies will build and operate AI factories, while others will rent. Countries are awakening to the need to treat their data as a national resource and AI factories as an essential national infrastructure. Data encodes a nation's history, knowledge, and culture, and can be transformed into the sovereign AI for its companies, startups, universities, and governments. NVIDIA builds the complete AI system and licenses NVIDIA AI Enterprise, the AI stack and operating system for AI factories. Production of digital intelligence tokens Data Tokens AI Factory Extending NVIDIA Networking to Scale Up & Scale Out AI in Any Data Center New NVLink and Spectrum-X increase networking opportunity beyond InfiniBand to every data center Generative AI Is a Data Center-Scale Computing Workload Limitless scaling with NVLINK + InfiniBand or Spectrum-X NVIDIA NVLink Fastest Interconnect for GPU Scale-Up NVIDIA InfiniBand Supercomputing and Dedicated AI Factories NVIDIA Spectrum-X Ethernet Optimized for Multi-Tenant AI Factories# of GPU in a Data Center NVIDIA Spectrum-X AI Ethernet Fabric 10 100 1K 100K10K 1M+ AI Performance InfiniBand NVLink + InfiniBand / Spectrum-X Traditional Ethernet Accelerated Computing Starts With CUDA Libraries Unlike CPU general-purpose computing, GPU- accelerated computing requires software and algorithms to be redesigned. Software is not automatically accelerated in the presence of a GPU or accelerator. NVIDIA CUDA libraries encapsulate NVIDIA-engineered algorithms that enable applications to be accelerated on NVIDIA‚Äôs installed base. They deliver dramatically higher performance‚Äîcompared to CPU-only alternatives‚Äîacross application domains, including AI and high-performance computing, and significantly reduce runtime, cost, and energy, while increasing scale. With over 400 CUDA libraries, NVIDIA can address many major workloads across a wide range of industries. As new libraries become available, they unlock new markets adding to our long-term opportunity. Delivering up to 200X speedup across major workloads Speech AI Riva, TensorRT, Triton Inference Server, NeMo, cuBLAS, cuDNN, cuFFT, CUTLASS ~30X Recommender Systems Merlin, HugeCTR, TensorRT, Triton Inference Server, cuBLAS, cuDNN, cuFFT, cuSPARSE, CUTLASS, Magnum IO, NCCL, cuVS ~50X Deep Learning cuDNN, CUTLASS, Megatron, TensorRT, TRT LLM, NCCL, NV-Triton, CUDA-optimized PyTorch, Tensorflow, Triton, Jax ~100X Science Earth-2 CorrDiff, Holoscan, Parabricks, Monai, Modulus, Warp, cuLitho, cuQuantum, CUDA-Q, AmgX, cuDSS, cuFFT, cuSOLVER, cuBLAS, cuSPARSE, cuTENSOR, cuGraph, Magnum IO, NCCL, NVSHMEM, RAFT, cuNumeric, Sionna ~100X Agentic and Physical AI ACE, Riva, Nemo, Tokkio Digital Human, Holoscan, Metropolis, Omniverse, Isaac, DRIVE, cuLitho, cuMotion, cuOpt, Aerial CUDA-accelerated RAN, Sionna, fVDB, PhysX, Warp, NVblox ~100X Computer Vision CV-CUDA, Deepstream, TAO, Holoscan, cuCIM, TensorRT, Triton Inference Server, DALI, nvImageCodec, cuDNN, nvJPEG, nvJPEG2000, nvTIFF, NPP, Video Codec SDK, Magnum IO, NCCL, cuVS, DALI ~200X Data Processing cuVS, cuDF-Spark, cuDF-pandas, cuDF-Polars, cuGraph, cuML, XGBoost, RAPIDS, NeMo Curator, cuSOLVER, cuIO ~200X Accelerated Computing Is Sustainable Computing Order of magnitude more energy efficient Energy Usage in AI Inference GPT-MoE-1.8T energy per token Accelerated computing requires higher peak power consumption than CPUs, however, completes workloads significantly faster and consumes less total energy Time(sec) Server TDP (kW) Kepler 42000 Joules/Token Pascal 17640 J/Token Volta 1200 J/Token Ampere 150 J/Token Hopper 10 J/Token Blackwell 0.4 J/Token 2014 2024 Accelerated computing enables full-stack optimization from algorithm to GPU architecture, such as Tensor Core Transformer Engine; LLM energy efficiency improved 100,000X in the past 10 years CPU NVIDIA AI Scaling Laws Drive Exponential Demand for Compute New OpenAI o1 Long ‚Äúthinking time‚Äù creates a new way to scale Inference compute scales exponentially with larger models, multimodality, large context, low latency, and now long ‚Äúthinking time‚Äù Training compute scales exponentially with larger models, multimodality, reinforcement learning, and synthetic data generationTraining Compute Inference Compute o1 NVIDIA Is the Leading Inference Platform Inference compute scales exponentially with ‚Äúlong thinking‚Äù Flash Attention KVCache PageAttention Distillation Pruning & Quantization Neural Architecture Search Disaggregated Serving Speculative Decoding Multi-GPU, Multi-Node Hopper inference performance increased 5X in 1 year with rapid algorithm innovations enabled by rich NVIDIA CUDA ecosystem Installed base & CUDA ‚ûî rapid software innovation ‚ûî performance ‚ûî lower inference cost ‚ûî increase demand ‚ûî increase installed base Inference compute scaling exponentially with large multimodal models, chain-of-thought, reasoning, agents, and low-latency responses GB200 NVL72 NVLink Switches 130 TB/s All-to-All BW One Giant Blackwell 1.44 EF FP4 576TB/s HBM3e NVIDIA NVLink Enables New Level of AI Training & Inference Scaling NVLink Switch GB200 NVL72 NVLink Switches 130 TB/s All-to-All BW One Giant Blackwell 1.44 EF FP4 576TB/s HBM3e Ecosystem NVIDIA AI Platform and Ecosystem Reaches Every Market Every workload to address the world‚Äôs industries Accelerate Every Workload Full-Stack, Entire AI Infrastructure Software Data Pre- Processing Training Post Training e.g., SDG Agentic AI Inference Robotic AI Inference AI Infrastructure AI Technology Every Cloud OEMs and ODMs PC and Workstations Edge and Robotics Full-Stack Compute-to-Networking Sovereign AI Regional CSPs Telcos Internet Services Public Clouds Heavy Industries Enterprises Auto, Healthcare, Logistics, Energy, FSI, etc. AI Startups SaaS Social Media Platforms NVIDIA AI Enterprise Enables IT Ecosystem With State-of-the-Art AI Models and Libraries to Build Agentic AI . . . Cloud and On-Prem Infrastructure System Integrators . . . Enterprise ISVs NVIDIA AI Enterprise Ecosystem NVIDIA NeMo User NVIDIA NeMo Retriever Vector Database Action Structured Database NVIDIA NIM Data Flywheel AI Agent . . . Data Platforms . . . NVIDIA Omniverse and AI Revolutionizing Manufacturing & Robotics 10M Factories 200K Warehouses 100M Cars Billions in Future The next AI wave is physical AI‚Äîmodels that can perceive, understand, and interact with the physical world. Physical AI will embody robotic systems‚Äîfrom autonomous vehicles to industrial robots and humanoids, to warehouses and factories. Three computers and software stacks are required to build physical AI: NVIDIA AI on DGX to train the AI model, NVIDIA Omniverse on OVX to teach, test, and validate the AI model's skills, and NVIDIA AGX to run the AI software on the robot. Enterprises license NVIDIA Omniverse at $4,500 per GPU per year. Sovereign AI Nations produce AI using their own data, infrastructure, workforce, and business networks Japan National Institute of Advanced Industrial Science and Technology (AIST) Switzerland Swisscom Group Ecuador Telconet Singapore Singapore Telecommunications Limited (Singtel) France Scaleway Vietnam FPT Smart Cloud Spain Barcelona Supercomputing Center Location of NVIDIA sovereign AI partners Sovereign AI Nations are awakening to the imperative to produce AI using their own infrastructure, data, workforces, and business networks. Nations are building domestic computing capacity. Some governments operate sovereign AI clouds in collaboration with state- owned telecommunications providers or utilities. Other governments partner with local cloud providers to deliver a shared AI computing infrastructure for public and private-sector use. NVIDIA‚Äôs ability to help build AI infrastructure with our end-to-end compute-to-networking technologies, full-stack software, AI expertise, and rich ecosystem of partners and customers allows sovereign AI and regional cloud providers to jump-start their countries‚Äô AI ambitions. $6,803 $12,690 $9,040 $37,134 $86,789 41% 47% 34% 61% 67% 30% 40% 50% 60% 70% $0 $10,000 $20,000 $30,000 $40,000 $50,000 $60,000 $70,000 $80,000 $90,000 FY21 FY22 FY23 FY24 FY25 Operating Income (Non-GAAP, $M) Operating Margin (Non-GAAP) $16,675 $26,914 $26,974 $60,922 $130,497 FY21 FY22 FY23 FY24 FY25 Driving Strong and Profitable Growth Fiscal year ends in January. Refer to Appendix for reconciliation of Non-GAAP measures. Operating margins rounded to the nearest percent. Revenue ($M) $4.7B $8.0B $3.8B $26.9B $60.7B FY21 FY22 FY23 FY24 FY25 Strong Cash Flow Generation Fiscal year ends in January. Refer to Appendix for reconciliation of Non-GAAP measures. Share Repurchase Utilized $33.7B of cash for repurchases in FY25 $38.7B remaining authorization as of the end of Q4 Dividend $834M in FY25 Dividend increased by 150% in Q2 FY25 Plan to Maintain1 Strategic Investments Growing Our Talent Platform Reach and Ecosystem Free Cash Flow (Non-GAAP) Capital Allocation 1 Subject to continuing determination by our Board of Directors. DRIVE Hyperion sensor architecture with AGX compute DRIVE AV & IX full-stack software for ADAS, AV, and AI cockpit DGX/HGX/MGX/IGX systems GPU | CPU | DPU | Networking NVIDIA AI software Our Market Platforms at a Glance FY25 Revenue $115.2B 5-YR CAGR 108% FY25 Revenue $11.4B 5-YR CAGR 16% FY25 Revenue $1.9B 5-YR CAGR 9% FY25 Revenue $1.7B 5-YR CAGR 19% GeForce GPUs for PC gaming GeForce NOW cloud gaming NVIDIA RTX GPUs for workstations Omniverse software Professional Visualization Automotive 9% of FY25 Revenue 1% of FY25 Revenue 1% of FY25 Revenue Data Center 88% of FY25 Revenue Gaming $6,696 $10,613 $15,005 $47,525 $115,186 FY21 FY22 FY23 FY24 FY25 Data Center The leading accelerated computing platform Leader in AI and HPC No. 1 in AI training and inference Used by all hyperscalers, major cloud computing providers, and over 40,000 companies Powers over 75% of the TOP500 supercomputers Growth Drivers Broad data center platform transition from general-purpose to accelerated computing Emergence of AI factories‚Äîoptimized for refining data and training, inferencing, and generating AI Broader and faster product launch cadence to meet a growing and diverse set of AI opportunities NVIDIA AI Enterprise/NIM for building and running enterprise AI applications 108% 5-YR CAGR Through FY25 Revenue ($M) Rubin Blackwell Hopper Blackwell-Ultra NVLink Switch 900 GB/sec CX7 SuperNIC Hopper GPU 6S HBM3 Hopper+ GPU 6S HBM3e BF3 SuperNIC Quantum-X400 Infiniband Switch Grace CPU NVLink 6 Switch 3600 GB/sec CX9 SuperNIC 1600 Gb/sec Rubin GPU 8S HBM4 Vera CPU X1600 IB/Ethernet Switch Rubin Ultra GPU 12S HBM4 2022 2024 20262023 2025 2027 One-Year Rhythm | Supercluster Scale | Full-Stack | CUDA Everywhere Supercharge AI scaling law X-Factors X-Factors X-Factors CX8 SuperNIC Spectrum Ultra X800 Ethernet Switch 512-Radix Blackwell Ultra GPU 288GB HBM3e More AI FLOPS $7,759 $12,462 $9,067 $10,447 $11,350 FY21 FY22 FY23 FY24 FY25 Gaming GeForce‚Äîworld‚Äôs largest gaming platform Leader in PC Gaming Strong No. 1 market position 15 of the top 15 most popular GPUs on Steam Leading performance and innovation 200M+ gamers on GeForce Growth Drivers Rising adoption of NVIDIA RTX in games Expanding universe of gamers and creators Gaming laptops and generative AI on PCs GeForce NOW cloud gaming 16% 5-YR CAGR Through FY25 Revenue ($M) $1,053 $2,111 $1,544 $1,553 $1,878 FY21 FY22 FY23 FY24 FY25 Professional Visualization Workstation graphics Leader in Workstation Graphics 95%+ market share in graphics for workstations 45M designers and creators Strong software ecosystem with over 100 RTX accelerated and supported applications Growth Drivers Generative AI adoption across design and creative industries Enterprise AI development, model fine-tuning, cross-industry Ray tracing revolutionizing design and content creation Expanding universe of designers and creators Omniverse for digital twins and collaborative 3D design Hybrid work environments Revenue ($M) 9% 5-YR CAGR Through FY25 $536 $566 $903 $1,091 $1,694 FY21 FY22 FY23 FY24 FY25 Automotive Autonomous vehicles and AI cockpits Leader in Autonomous Driving NVIDIA DRIVE an end-to-end autonomous vehicle (AV) and AI cockpit platform featuring a full software stack and powered by NVIDIA SoCs (systems-on-a-chip) in vehicles DRIVE Orin SoC ramp began in FY23 Next-generation DRIVE Thor SoC ramp to begin in FY26 Over 40 customers including 20 of top 30 EV makers, 7 of top 10 truck makers, 8 of top 10 robotaxi makers Growth Drivers Adoption of centralized car computing and software-defined vehicle architectures AV software and services: Mercedes-Benz Jaguar Land Rover Revenue ($M) 19% 5-YR CAGR Through FY25 The $1T installed base of general-purpose CPU data center infrastructure is being modernized to a new GPU-accelerated computing paradigm. The entire computing stack has been reinvented‚Äî from CPU to GPU, from coding to machine learning, from software to generative AI. Computers generate intelligence tokens, a new commodity. A new type of data center, AI factories, is expanding the data center footprint to $2T and beyond in the coming years. Eventually,companies in every industry will operate AI factories as the digital twin of their workforce, manufacturing plants, and products. A new industrial revolution has begun. Accelerated Computing and Generative AI Create Trillion-Dollar Opportunities GPU-Accelerated Data Centers AI Factories Traditional Data Centers General-Purpose Computing AI Accelerated Computing Financials Annual Cash & Cash Flow Metrics 5,822 9,108 5,641 28,090 64,089 FY21 FY22 FY23 FY24 FY25 6,803 12,690 9,040 37,134 86,789 FY21 FY22 FY23 FY24 FY25 4,677 8,049 3,750 26,947 60,724 FY21 FY22 FY23 FY24 FY25 11,561 21,208 13,296 25,984 43,210 FY21 FY22 FY23 FY24 FY25 Cash balance is defined as cash and cash equivalents plus marketable securities Refer to Appendix for reconciliation of non-GAAP measures Free Cash Flow (Non-GAAP)‚Äî$M Cash Balance‚Äî$M Operating Income (Non-GAAP)‚Äî$M Operating Cash Flow‚Äî$M Corporate Sustainability Fast Company Magazine‚Äôs World‚Äôs Most Innovative Companies Fortune‚Äôs World‚Äôs Most Admired Companies Time Magazine‚Äôs 100 Most Influential Companies Wall Street Journal‚Äôs Management Top 250‚ÄúAmerica‚Äôs Most Sustainable Companies‚Äù BARRON‚ÄôS ‚ÄúAmerica‚Äôs 100 Best Companies to Work For‚Äù FORTUNE ‚ÄúAmerica‚Äôs Most Responsible Companies‚Äù NEWSWEEK NVIDIA Blackwell GPUs are as much as 20X more energy efficient than CPUs for certain AI and HPC workloads On track to source 100% renewable electricity for offices and data centers under operational control by end of FY25 A Place for People to Do Their Life‚Äôs WorkEnvironmentally Conscious On track to engage manufacturing suppliers comprising at least 67% of scope 3 category 1 GHG emissions with the goal of effecting supplier adoption of science-based targets by end of FY26 Management 92% of directors are independent Corporate Governance ‚ÄúBest Places to Work‚Äù GLASSDOOR Reconciliation of Non-GAAP to GAAP Financial Measures Operating Income and Margin ($ in Millions and Margin Percentage) Non-GAAP Acquisition Termination Cost Acquisition-Related and Other Costs (A) Stock-Based Compensation (B) Other (C) GAAP FY 2021 $6,803 ‚Äî (836) (1,397) (38) $4,532 40.8% ‚Äî (5.0) (8.4) (0.2) 27.2% FY 2022 $12,690 ‚Äî (636) (2,004) (9) $10,041 47.2% ‚Äî (2.5) (7.4) ‚Äî 37.3% FY 2023 $9,040 (1,353) (674) (2,710) (79) $4,224 33.5% (5.0) (2.5) (10.0) (0.3) 15.7% FY 2024 $37,134 ‚Äî (583) (3,549) (30) $32,972 61.0% ‚Äî (1.0) (5.8) (0.1) 54.1% FY 2025 $86,789 ‚Äî (602) (4,737) 3 $81,453 66.5% ‚Äî (0.5) (3.6) ‚Äî 62.4% Reconciliation of Non-GAAP to GAAP Financial Measures A. Consists of amortization of acquisition-related intangible assets, inventory step-up, transaction costs, compensation charges, and other costs B. Stock-based compensation charge was allocated to cost of goods sold, research and development expense, and sales, general and administrative expense C. Comprises of legal settlement cost, contributions, restructuring costs and assets held for sale related adjustments ($ in Millions) Free Cash Flow Purchases Related to Property and Equipment and Intangible Assets Principal Payments on Property and Equipment and Intangible Assets Net Cash Provided by Operating Activities FY 2021 $4,677 1,128 17 $5,822 FY 2022 $8,049 976 83 $9,108 FY 2023 $3,750 1,833 58 $5,641 FY 2024 $26,947 1,069 74 $28,090 FY 2025 $60,724 3,236 129 $64,089 Reconciliation of Non-GAAP to GAAP Financial Measures (contd.)